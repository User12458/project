{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install seqeval evaluate -q\n",
    "!pip install transformers -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-01T20:55:04.945993Z",
     "iopub.status.idle": "2025-10-01T20:55:14.710832Z",
     "shell.execute_reply": "2025-10-01T20:55:14.710212Z",
     "shell.execute_reply.started": "2025-10-01T20:55:04.946325Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 20:55:10.508230: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759352110.530292    4102 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759352110.537069    4102 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import random\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    DataCollatorForTokenClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    "    set_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:55:14.715614Z",
     "iopub.status.busy": "2025-10-01T20:55:14.715335Z",
     "iopub.status.idle": "2025-10-01T20:55:14.720553Z",
     "shell.execute_reply": "2025-10-01T20:55:14.720092Z",
     "shell.execute_reply.started": "2025-10-01T20:55:14.715598Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Sets the seed for reproducibility across multiple libraries.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed) \n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed) \n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "set_seed(56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:55:14.722018Z",
     "iopub.status.busy": "2025-10-01T20:55:14.721842Z",
     "iopub.status.idle": "2025-10-01T20:55:15.178576Z",
     "shell.execute_reply": "2025-10-01T20:55:15.177974Z",
     "shell.execute_reply.started": "2025-10-01T20:55:14.722003Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./train.csv',sep=';')\n",
    "sample_sub = pd.read_csv('./submission.csv', sep=';')\n",
    "train_data['annotation'] = train_data['annotation'].apply(eval)\n",
    "train_data['annotation'] = train_data['annotation'].apply(lambda x: [(y[0],y[1],y[2].replace('0','O')) for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:55:15.179428Z",
     "iopub.status.busy": "2025-10-01T20:55:15.179235Z",
     "iopub.status.idle": "2025-10-01T20:55:15.216127Z",
     "shell.execute_reply": "2025-10-01T20:55:15.215540Z",
     "shell.execute_reply.started": "2025-10-01T20:55:15.179411Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_label_list(entity_types: List[str]) -> List[str]:\n",
    "    labels = ['O']\n",
    "    for ent in entity_types:\n",
    "        labels.append(f'B-{ent}')\n",
    "        labels.append(f'I-{ent}')\n",
    "    return labels\n",
    "\n",
    "entity_types = ['BRAND', 'PERCENT', 'TYPE', 'VOLUME']\n",
    "label_list = build_label_list(entity_types) \n",
    "label2id = {l: i for i, l in enumerate(label_list)}\n",
    "id2label = {i: l for l, i in label2id.items()}\n",
    "train_data['annotation'] = train_data['annotation'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:55:15.216987Z",
     "iopub.status.busy": "2025-10-01T20:55:15.216794Z",
     "iopub.status.idle": "2025-10-01T20:55:15.229002Z",
     "shell.execute_reply": "2025-10-01T20:55:15.228499Z",
     "shell.execute_reply.started": "2025-10-01T20:55:15.216961Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "WORD_RE = re.compile(r\"\\S+\")\n",
    "\n",
    "def strip_bio(lab):\n",
    "    if not lab:\n",
    "        return \"\"\n",
    "    lab = str(lab)\n",
    "    if lab == \"O\":\n",
    "        return \"\"\n",
    "    if lab.startswith((\"B-\", \"I-\")):\n",
    "        return lab[2:]\n",
    "    return lab\n",
    "\n",
    "def normalize_spans(spans):\n",
    "    norm = []\n",
    "    for s, e, lab in spans:\n",
    "        ent = strip_bio(lab)\n",
    "        if ent:\n",
    "            norm.append((int(s), int(e), ent))\n",
    "    return norm\n",
    "\n",
    "def compute_overlap(s1: int, e1: int, s2: int, e2: int) -> int:\n",
    "    return max(0, min(e1, e2) - max(s1, s2))\n",
    "\n",
    "def split_words_with_spans(text: str):\n",
    "    return [(m.group(0), m.start(), m.end()) for m in WORD_RE.finditer(text)]\n",
    "\n",
    "def tokenize_and_align_labels(\n",
    "    examples: Dict[str, List[Any]],\n",
    "    tokenizer,\n",
    "    label2id: Dict[str, int],\n",
    "    label_all_tokens: bool = True,\n",
    "    max_length: int = 256\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    На входе:\n",
    "      - examples['sample']: список текстов\n",
    "      - examples['annotation']: список списков спанов в виде строк \"[ (start, end, label), ... ]\"\n",
    "        (каждый элемент будет разобран через ast.literal_eval)\n",
    "    На выходе:\n",
    "      - tokenized inputs с полем 'labels' (список id меток для каждого токена; -100 для спец. токенов)\n",
    "    \"\"\"\n",
    "    texts = examples[\"sample\"]\n",
    "    batch_spans_raw = examples[\"annotation\"]\n",
    "    batch_spans = [normalize_spans(ast.literal_eval(sp)) for sp in batch_spans_raw]\n",
    "\n",
    "    batch_words = []\n",
    "    batch_word_labels = []\n",
    "\n",
    "    for text, spans in zip(texts, batch_spans):\n",
    "        word_triplets = split_words_with_spans(text)  # [(word, s, e), ...]\n",
    "        words = [w for w, _, _ in word_triplets]\n",
    "        batch_words.append(words)\n",
    "\n",
    "        per_word_labels = []\n",
    "        for _, w_start, w_end in word_triplets:\n",
    "            label = \"O\"\n",
    "            best_ent = None\n",
    "            best_ov = 0\n",
    "\n",
    "            for (s, e, ent_type) in spans:\n",
    "                ov = compute_overlap(s, e, w_start, w_end)\n",
    "                if ov > best_ov:\n",
    "                    best_ov = ov\n",
    "                    best_ent = (s, e, ent_type)\n",
    "\n",
    "            if best_ent is not None and best_ov > 0:\n",
    "                ent_start, ent_end, ent_type = best_ent\n",
    "                if w_start == ent_start:\n",
    "                    label = f\"B-{ent_type}\"\n",
    "                else:\n",
    "                    label = f\"I-{ent_type}\"\n",
    "\n",
    "            per_word_labels.append(label)\n",
    "\n",
    "        batch_word_labels.append(per_word_labels)\n",
    "\n",
    "    tokenized = tokenizer(\n",
    "        batch_words,\n",
    "        is_split_into_words=True,\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=max_length,\n",
    "        return_tensors=None \n",
    "    )\n",
    "\n",
    "    all_labels: List[List[int]] = []\n",
    "\n",
    "    for i in range(len(batch_words)):\n",
    "        word_ids = tokenized.word_ids(batch_index=i)  # список индексов слов для каждого токена\n",
    "        if word_ids is None:\n",
    "            raise ValueError(\"Tokenizer must be a fast tokenizer to use word_ids.\")\n",
    "\n",
    "        labels_ids: List[int] = []\n",
    "        prev_word_id = None\n",
    "        per_word = batch_word_labels[i]\n",
    "\n",
    "        for w_id in word_ids:\n",
    "            if w_id is None:\n",
    "                labels_ids.append(-100)  # спец. токены\n",
    "            else:\n",
    "                label_str = per_word[w_id]\n",
    "                if not label_all_tokens and w_id == prev_word_id:\n",
    "                    labels_ids.append(-100)  # только первый сабтокен помечаем\n",
    "                else:\n",
    "                    labels_ids.append(label2id[label_str])\n",
    "            prev_word_id = w_id\n",
    "\n",
    "        all_labels.append(labels_ids)\n",
    "\n",
    "    tokenized[\"labels\"] = all_labels\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:55:15.229991Z",
     "iopub.status.busy": "2025-10-01T20:55:15.229794Z",
     "iopub.status.idle": "2025-10-01T20:55:15.604150Z",
     "shell.execute_reply": "2025-10-01T20:55:15.603591Z",
     "shell.execute_reply.started": "2025-10-01T20:55:15.229967Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "examples = [\n",
    "    [\"йогурт 2%\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"йогурт 2,5\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"йогурт питьевой 1.5%\", [(0, 6, 'B-TYPE'), (7, 15, 'I-TYPE'), (16, 20, 'B-PERCENT')]],\n",
    "    [\"ряженка 4 %\", [(0, 7, 'B-TYPE'), (8, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]],\n",
    "    [\"ряженка 4%\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT')]],\n",
    "    [\"кефир 2.5%\", [(0, 5, 'B-TYPE'), (6, 10, 'B-PERCENT')]],\n",
    "    [\"кефир 0%\", [(0, 5, 'B-TYPE'), (6, 8, 'B-PERCENT')]],\n",
    "    [\"кефир бифидум 1\", [(0, 5, 'B-TYPE'), (6, 13, 'I-TYPE'), (14, 15, 'B-PERCENT')]],\n",
    "    [\"молоко 2 %\", [(0, 6, 'B-TYPE'), (7, 8, 'B-PERCENT'), (9, 10, 'I-PERCENT')]],\n",
    "    [\"молоко 2.5\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"молоко пастеризованное 3,2%\", [(0, 6, 'B-TYPE'), (7, 22, 'I-TYPE'), (23, 27, 'B-PERCENT')]],\n",
    "    [\"творог мягкий 0.5%\", [(0, 6, 'B-TYPE'), (7, 13, 'I-TYPE'), (14, 18, 'B-PERCENT')]],\n",
    "    [\"творог 18%\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"творог зерненый 5\", [(0, 6, 'B-TYPE'), (7, 15, 'I-TYPE'), (16, 17, 'B-PERCENT')]],\n",
    "    [\"сметана 30%\", [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT')]],\n",
    "    [\"сметана 30\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT')]],\n",
    "    [\"сметана фермерская 25 %\", [(0, 7, 'B-TYPE'), (8, 18, 'I-TYPE'), (19, 21, 'B-PERCENT'), (22, 23, 'I-PERCENT')]],\n",
    "    [\"сыр плавленый 45%\", [(0, 3, 'B-TYPE'), (4, 13, 'I-TYPE'), (14, 17, 'B-PERCENT')]],\n",
    "    [\"сыр твердый 50\", [(0, 3, 'B-TYPE'), (4, 11, 'I-TYPE'), (12, 14, 'B-PERCENT')]],\n",
    "    [\"сыр 45 %\", [(0, 3, 'B-TYPE'), (4, 6, 'B-PERCENT'), (7, 8, 'I-PERCENT')]],\n",
    "    [\"масло сливочное 62%\", [(0, 5, 'B-TYPE'), (6, 15, 'I-TYPE'), (16, 19, 'B-PERCENT')]],\n",
    "    [\"масло 72.5\", [(0, 5, 'B-TYPE'), (6, 10, 'B-PERCENT')]],\n",
    "    [\"масло топленое 99\", [(0, 5, 'B-TYPE'), (6, 14, 'I-TYPE'), (15, 17, 'B-PERCENT')]],\n",
    "    [\"сливки 15%\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"сливки 15\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"сливки взбитые 35 %\", [(0, 6, 'B-TYPE'), (7, 14, 'I-TYPE'), (15, 17, 'B-PERCENT'), (18, 19, 'I-PERCENT')]],\n",
    "    [\"простоквашино молоко 3.2\", [(0, 13, 'B-BRAND'), (14, 20, 'B-TYPE'), (21, 24, 'B-PERCENT')]],\n",
    "    [\"домик в деревне кефир 1%\", [(0, 15, 'B-BRAND'), (16, 21, 'B-TYPE'), (22, 24, 'B-PERCENT')]],\n",
    "    [\"йогурт греческий 0\", [(0, 6, 'B-TYPE'), (7, 16, 'I-TYPE'), (17, 18, 'B-PERCENT')]],\n",
    "    [\"ряженка 2.5%\", [(0, 7, 'B-TYPE'), (8, 12, 'B-PERCENT')]],\n",
    "    [\"кефир 3,2\", [(0, 5, 'B-TYPE'), (6, 9, 'B-PERCENT')]],\n",
    "    [\"молоко 0.5 %\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT'), (11, 12, 'I-PERCENT')]],\n",
    "    [\"творог 0%\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"сметана 18 %\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT'), (11, 12, 'I-PERCENT')]],\n",
    "    [\"сыр мягкий 20%\", [(0, 3, 'B-TYPE'), (4, 10, 'I-TYPE'), (11, 14, 'B-PERCENT')]],\n",
    "    [\"масло растительное 100%\", [(0, 5, 'B-TYPE'), (6, 18, 'I-TYPE'), (19, 23, 'B-PERCENT')]],\n",
    "    [\"сливки 25%\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"йогурт 1.5\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"ряженка 3 %\", [(0, 7, 'B-TYPE'), (8, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]],\n",
    "    [\"кефир обезжиренный 0\", [(0, 5, 'B-TYPE'), (6, 18, 'I-TYPE'), (19, 20, 'B-PERCENT')]],\n",
    "    [\"молоко 4%\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"творог 2 %\", [(0, 6, 'B-TYPE'), (7, 8, 'B-PERCENT'), (9, 10, 'I-PERCENT')]],\n",
    "    [\"сметана 12%\", [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT')]],\n",
    "    [\"сыр 55\", [(0, 3, 'B-TYPE'), (4, 6, 'B-PERCENT')]],\n",
    "    [\"масло 82.5%\", [(0, 5, 'B-TYPE'), (6, 11, 'B-PERCENT')]],\n",
    "    [\"сливки 40\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"йогурт 3.2 %\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT'), (11, 12, 'I-PERCENT')]],\n",
    "    [\"ряженка 1%\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT')]],\n",
    "    [\"кефир 2 %\", [(0, 5, 'B-TYPE'), (6, 7, 'B-PERCENT'), (8, 9, 'I-PERCENT')]],\n",
    "    [\"молоко топленое 4\", [(0, 6, 'B-TYPE'), (7, 15, 'I-TYPE'), (16, 17, 'B-PERCENT')]],\n",
    "    [\"творог 15%\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"сметана 35\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT')]],\n",
    "    [\"сыр с плесенью 50%\", [(0, 3, 'B-TYPE'), (4, 14, 'I-TYPE'), (15, 18, 'B-PERCENT')]],\n",
    "    [\"масло кокосовое 99%\", [(0, 5, 'B-TYPE'), (6, 15, 'I-TYPE'), (16, 19, 'B-PERCENT')]],\n",
    "    [\"сливки 12 %\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]],\n",
    "    [\"йогурт натуральный 2.5\", [(0, 6, 'B-TYPE'), (7, 18, 'I-TYPE'), (19, 22, 'B-PERCENT')]],\n",
    "    [\"ряженка 0.5%\", [(0, 7, 'B-TYPE'), (8, 12, 'B-PERCENT')]],\n",
    "    [\"кефир 4%\", [(0, 5, 'B-TYPE'), (6, 8, 'B-PERCENT')]],\n",
    "    [\"молоко 1.5%\", [(0, 6, 'B-TYPE'), (7, 11, 'B-PERCENT')]],\n",
    "    [\"творог обезжиренный 0 %\", [(0, 6, 'B-TYPE'), (7, 19, 'I-TYPE'), (20, 21, 'B-PERCENT'), (22, 23, 'I-PERCENT')]],\n",
    "    [\"сметана 40%\", [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT')]],\n",
    "    [\"сыр 60 %\", [(0, 3, 'B-TYPE'), (4, 6, 'B-PERCENT'), (7, 8, 'I-PERCENT')]],\n",
    "    [\"масло 90\", [(0, 5, 'B-TYPE'), (6, 8, 'B-PERCENT')]],\n",
    "    [\"сливки стерилизованные 10\", [(0, 6, 'B-TYPE'), (7, 23, 'I-TYPE'), (24, 26, 'B-PERCENT')]],\n",
    "    [\"йогурт 0 %\", [(0, 6, 'B-TYPE'), (7, 8, 'B-PERCENT'), (9, 10, 'I-PERCENT')]],\n",
    "    [\"ряженка 5\", [(0, 7, 'B-TYPE'), (8, 9, 'B-PERCENT')]],\n",
    "    [\"кефир фруктовый 1.5 %\", [(0, 5, 'B-TYPE'), (6, 15, 'I-TYPE'), (16, 19, 'B-PERCENT'), (20, 21, 'I-PERCENT')]],\n",
    "    [\"молоко 3%\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"творог 3.5\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"сметана домашняя 20\", [(0, 7, 'B-TYPE'), (8, 16, 'I-TYPE'), (17, 19, 'B-PERCENT')]],\n",
    "    [\"сыр кремовый 30%\", [(0, 3, 'B-TYPE'), (4, 12, 'I-TYPE'), (13, 16, 'B-PERCENT')]],\n",
    "    [\"масло 75 %\", [(0, 5, 'B-TYPE'), (6, 8, 'B-PERCENT'), (9, 10, 'I-PERCENT')]],\n",
    "    [\"сливки 18%\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"йогурт 4 %\", [(0, 6, 'B-TYPE'), (7, 8, 'B-PERCENT'), (9, 10, 'I-PERCENT')]],\n",
    "    [\"ряженка 2%\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT')]],\n",
    "    [\"кефир 0.1%\", [(0, 5, 'B-TYPE'), (6, 10, 'B-PERCENT')]],\n",
    "    [\"молоко цельное 3.5 %\", [(0, 6, 'B-TYPE'), (7, 14, 'I-TYPE'), (15, 18, 'B-PERCENT'), (19, 20, 'I-PERCENT')]],\n",
    "    [\"творог 12\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"сметана 22%\", [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT')]],\n",
    "    [\"сыр 40\", [(0, 3, 'B-TYPE'), (4, 6, 'B-PERCENT')]],\n",
    "    [\"масло сливочное 80\", [(0, 5, 'B-TYPE'), (6, 15, 'I-TYPE'), (16, 18, 'B-PERCENT')]],\n",
    "    [\"сливки 22 %\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]],\n",
    "    [\"йогурт обезжиренный 0\", [(0, 6, 'B-TYPE'), (7, 19, 'I-TYPE'), (20, 21, 'B-PERCENT')]],\n",
    "    [\"ряженка 3.2\", [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT')]],\n",
    "    [\"кефир 2.0 %\", [(0, 5, 'B-TYPE'), (6, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]],\n",
    "    [\"молоко 2.0\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"творог классический 9%\", [(0, 6, 'B-TYPE'), (7, 19, 'I-TYPE'), (20, 22, 'B-PERCENT')]],\n",
    "    [\"сметана 28\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT')]],\n",
    "    [\"сыр пармезан 32%\", [(0, 3, 'B-TYPE'), (4, 12, 'I-TYPE'), (13, 16, 'B-PERCENT')]],\n",
    "    [\"масло 85%\", [(0, 5, 'B-TYPE'), (6, 9, 'B-PERCENT')]],\n",
    "    [\"сливки 28\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"йогурт 5%\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"ряженка 4.0 %\", [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT'), (12, 13, 'I-PERCENT')]],\n",
    "    [\"кефир 3%\", [(0, 5, 'B-TYPE'), (6, 8, 'B-PERCENT')]],\n",
    "    [\"молоко 0%\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"творог 4%\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"сметана 15\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT')]],\n",
    "    [\"сыр чеддер 48%\", [(0, 3, 'B-TYPE'), (4, 10, 'I-TYPE'), (11, 14, 'B-PERCENT')]],\n",
    "    [\"масло топленое 98 %\", [(0, 5, 'B-TYPE'), (6, 14, 'I-TYPE'), (15, 17, 'B-PERCENT'), (18, 19, 'I-PERCENT')]],\n",
    "    [\"сливки 35%\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"йогурт 2.0%\", [(0, 6, 'B-TYPE'), (7, 11, 'B-PERCENT')]],\n",
    "    [\"ряженка 1.5\", [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT')]],\n",
    "    [\"кефир 1.0\", [(0, 5, 'B-TYPE'), (6, 9, 'B-PERCENT')]],\n",
    "    [\"молоко ультрапастеризованное 1%\", [(0, 6, 'B-TYPE'), (7, 28, 'I-TYPE'), (29, 31, 'B-PERCENT')]],\n",
    "    [\"творог 6 %\", [(0, 6, 'B-TYPE'), (7, 8, 'B-PERCENT'), (9, 10, 'I-PERCENT')]],\n",
    "    [\"сметана 10 %\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT'), (11, 12, 'I-PERCENT')]],\n",
    "    [\"сыр легкий 10\", [(0, 3, 'B-TYPE'), (4, 10, 'I-TYPE'), (11, 13, 'B-PERCENT')]],\n",
    "    [\"масло сливочное 70%\", [(0, 5, 'B-TYPE'), (6, 15, 'I-TYPE'), (16, 19, 'B-PERCENT')]],\n",
    "    [\"сливки 30 %\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]],\n",
    "    [\"йогурт 3%\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"ряженка 2.0%\", [(0, 7, 'B-TYPE'), (8, 12, 'B-PERCENT')]],\n",
    "    [\"кефир 0 %\", [(0, 5, 'B-TYPE'), (6, 7, 'B-PERCENT'), (8, 9, 'I-PERCENT')]],\n",
    "    [\"молоко 4.5\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"творог мягкий 2%\", [(0, 6, 'B-TYPE'), (7, 13, 'I-TYPE'), (14, 16, 'B-PERCENT')]],\n",
    "    [\"сметана 25%\", [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT')]],\n",
    "    [\"сыр 25 %\", [(0, 3, 'B-TYPE'), (4, 6, 'B-PERCENT'), (7, 8, 'I-PERCENT')]],\n",
    "    [\"масло 60\", [(0, 5, 'B-TYPE'), (6, 8, 'B-PERCENT')]],\n",
    "    [\"сливки 5%\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"йогурт питьевой 0.5 %\", [(0, 6, 'B-TYPE'), (7, 15, 'I-TYPE'), (16, 19, 'B-PERCENT'), (20, 21, 'I-PERCENT')]],\n",
    "    [\"ряженка 3%\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT')]],\n",
    "    [\"кефир 2.5\", [(0, 5, 'B-TYPE'), (6, 9, 'B-PERCENT')]],\n",
    "    [\"молоко 3.5%\", [(0, 6, 'B-TYPE'), (7, 11, 'B-PERCENT')]],\n",
    "    [\"творог 7\", [(0, 6, 'B-TYPE'), (7, 8, 'B-PERCENT')]],\n",
    "    [\"сметана 5 %\", [(0, 7, 'B-TYPE'), (8, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]],\n",
    "    [\"сыр твердый 45 %\", [(0, 3, 'B-TYPE'), (4, 11, 'I-TYPE'), (12, 14, 'B-PERCENT'), (15, 16, 'I-PERCENT')]],\n",
    "    [\"масло 72 %\", [(0, 5, 'B-TYPE'), (6, 8, 'B-PERCENT'), (9, 10, 'I-PERCENT')]],\n",
    "    [\"сливки 40%\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"йогурт 1 %\", [(0, 6, 'B-TYPE'), (7, 8, 'B-PERCENT'), (9, 10, 'I-PERCENT')]],\n",
    "    [\"ряженка 0%\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT')]],\n",
    "    [\"кефир 3.5 %\", [(0, 5, 'B-TYPE'), (6, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]],\n",
    "    [\"молоко 2.5 %\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT'), (11, 12, 'I-PERCENT')]],\n",
    "    [\"творог 10%\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"сметана 30 %\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT'), (11, 12, 'I-PERCENT')]],\n",
    "    [\"сыр 35\", [(0, 3, 'B-TYPE'), (4, 6, 'B-PERCENT')]],\n",
    "    [\"масло сливочное 85 %\", [(0, 5, 'B-TYPE'), (6, 15, 'I-TYPE'), (16, 18, 'B-PERCENT'), (19, 20, 'I-PERCENT')]],\n",
    "    [\"сливки 15 %\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]],\n",
    "    [\"йогурт 4.5\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"ряженка 5%\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT')]],\n",
    "    [\"кефир 1.5\", [(0, 5, 'B-TYPE'), (6, 9, 'B-PERCENT')]],\n",
    "    [\"молоко 1\", [(0, 6, 'B-TYPE'), (7, 8, 'B-PERCENT')]],\n",
    "    [\"творог 0.5 %\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT'), (11, 12, 'I-PERCENT')]],\n",
    "    [\"сметана 18%\", [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT')]],\n",
    "    [\"сыр легкий 20 %\", [(0, 3, 'B-TYPE'), (4, 10, 'I-TYPE'), (11, 13, 'B-PERCENT'), (14, 15, 'I-PERCENT')]],\n",
    "    [\"масло 82\", [(0, 5, 'B-TYPE'), (6, 8, 'B-PERCENT')]],\n",
    "    [\"сливки 20 %\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]],\n",
    "    [\"йогурт 2.5 %\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT'), (11, 12, 'I-PERCENT')]],\n",
    "    [\"ряженка 4 %\", [(0, 7, 'B-TYPE'), (8, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]],\n",
    "    [\"кефир 0.5\", [(0, 5, 'B-TYPE'), (6, 9, 'B-PERCENT')]],\n",
    "    [\"молоко 3.2 %\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT'), (11, 12, 'I-PERCENT')]],\n",
    "    [\"творог 5 %\", [(0, 6, 'B-TYPE'), (7, 8, 'B-PERCENT'), (9, 10, 'I-PERCENT')]],\n",
    "    [\"сметана 20 %\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT'), (11, 12, 'I-PERCENT')]],\n",
    "    [\"сыр 50%\", [(0, 3, 'B-TYPE'), (4, 7, 'B-PERCENT')]],\n",
    "    [\"масло сливочное 72 %\", [(0, 5, 'B-TYPE'), (6, 15, 'I-TYPE'), (16, 18, 'B-PERCENT'), (19, 20, 'I-PERCENT')]],\n",
    "    [\"сливки 33\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"йогурт 0.1%\", [(0, 6, 'B-TYPE'), (7, 11, 'B-PERCENT')]],\n",
    "    [\"ряженка 2.5 %\", [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT'), (12, 13, 'I-PERCENT')]],\n",
    "    [\"кефир 2%\", [(0, 5, 'B-TYPE'), (6, 8, 'B-PERCENT')]],\n",
    "    [\"молоко 0.5\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"творог 9%\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"сметана 25 %\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT'), (11, 12, 'I-PERCENT')]],\n",
    "    [\"сыр 15%\", [(0, 3, 'B-TYPE'), (4, 7, 'B-PERCENT')]],\n",
    "    [\"масло 80 %\", [(0, 5, 'B-TYPE'), (6, 8, 'B-PERCENT'), (9, 10, 'I-PERCENT')]],\n",
    "    [\"сливки 10\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"балтика 1\", [(0, 7, 'B-BRAND'), (8, 9, 'B-PERCENT')]],\n",
    "    [\"нестожен молоко 2\", [(0, 8, 'B-BRAND'), (9, 15, 'B-TYPE'), (16, 17, 'B-PERCENT')]],\n",
    "    [\"простоквашино сметана 15%\", [(0, 13, 'B-BRAND'), (14, 21, 'B-TYPE'), (22, 25, 'B-PERCENT')]],\n",
    "    [\"домик в деревне творог 5\", [(0, 15, 'B-BRAND'), (16, 22, 'B-TYPE'), (23, 24, 'B-PERCENT')]],\n",
    "    [\"балтика кефир 0%\", [(0, 7, 'B-BRAND'), (8, 13, 'B-TYPE'), (14, 16, 'B-PERCENT')]],\n",
    "    [\"нестожен йогурт 1.5\", [(0, 8, 'B-BRAND'), (9, 15, 'B-TYPE'), (16, 19, 'B-PERCENT')]],\n",
    "    [\"простоквашино сливки 20 %\", [(0, 13, 'B-BRAND'), (14, 20, 'B-TYPE'), (21, 23, 'B-PERCENT'), (24, 25, 'I-PERCENT')]],\n",
    "    [\"домик в деревне сыр 45\", [(0, 15, 'B-BRAND'), (16, 19, 'B-TYPE'), (20, 22, 'B-PERCENT')]],\n",
    "    [\"балтика ряженка 3,2\", [(0, 7, 'B-BRAND'), (8, 15, 'B-TYPE'), (16, 19, 'B-PERCENT')]],\n",
    "    [\"нестожен масло 82%\", [(0, 8, 'B-BRAND'), (9, 14, 'B-TYPE'), (15, 18, 'B-PERCENT')]],\n",
    "    [\"простоквашино творог 9 %\", [(0, 13, 'B-BRAND'), (14, 20, 'B-TYPE'), (21, 22, 'B-PERCENT'), (23, 24, 'I-PERCENT')]],\n",
    "    [\"домик в деревне молоко 3.2%\", [(0, 15, 'B-BRAND'), (16, 22, 'B-TYPE'), (23, 27, 'B-PERCENT')]],\n",
    "    [\"балтика сметана 10\", [(0, 7, 'B-BRAND'), (8, 15, 'B-TYPE'), (16, 18, 'B-PERCENT')]],\n",
    "    [\"нестожен кефир 2.5 %\", [(0, 8, 'B-BRAND'), (9, 14, 'B-TYPE'), (15, 18, 'B-PERCENT'), (19, 20, 'I-PERCENT')]],\n",
    "    [\"простоквашино йогурт 0\", [(0, 13, 'B-BRAND'), (14, 20, 'B-TYPE'), (21, 22, 'B-PERCENT')]],\n",
    "    [\"домик в деревне сливки 33%\", [(0, 15, 'B-BRAND'), (16, 22, 'B-TYPE'), (23, 26, 'B-PERCENT')]],\n",
    "    [\"балтика сыр легкий 15\", [(0, 7, 'B-BRAND'), (8, 11, 'B-TYPE'), (12, 18, 'I-TYPE'), (19, 21, 'B-PERCENT')]],\n",
    "    [\"нестожен ряженка 4%\", [(0, 8, 'B-BRAND'), (9, 16, 'B-TYPE'), (17, 19, 'B-PERCENT')]],\n",
    "    [\"простоквашино масло сливочное 72\", [(0, 13, 'B-BRAND'), (14, 19, 'B-TYPE'), (20, 29, 'I-TYPE'), (30, 32, 'B-PERCENT')]],\n",
    "    [\"домик в деревне сметана 20%\", [(0, 15, 'B-BRAND'), (16, 23, 'B-TYPE'), (24, 27, 'B-PERCENT')]],\n",
    "    [\"балтика молоко 1 %\", [(0, 7, 'B-BRAND'), (8, 14, 'B-TYPE'), (15, 16, 'B-PERCENT'), (17, 18, 'I-PERCENT')]],\n",
    "    [\"нестожен творог 5\", [(0, 8, 'B-BRAND'), (9, 15, 'B-TYPE'), (16, 17, 'B-PERCENT')]],\n",
    "    [\"простоквашино кефир 1\", [(0, 13, 'B-BRAND'), (14, 19, 'B-TYPE'), (20, 21, 'B-PERCENT')]],\n",
    "    [\"домик в деревне йогурт 2.5\", [(0, 15, 'B-BRAND'), (16, 22, 'B-TYPE'), (23, 26, 'B-PERCENT')]],\n",
    "    [\"балтика сливки 10%\", [(0, 7, 'B-BRAND'), (8, 14, 'B-TYPE'), (15, 18, 'B-PERCENT')]],\n",
    "    [\"нестожен сыр 45 %\", [(0, 8, 'B-BRAND'), (9, 12, 'B-TYPE'), (13, 15, 'B-PERCENT'), (16, 17, 'I-PERCENT')]],\n",
    "    [\"простоквашино ряженка 3.2\", [(0, 13, 'B-BRAND'), (14, 21, 'B-TYPE'), (22, 25, 'B-PERCENT')]],\n",
    "    [\"домик в деревне масло 82\", [(0, 15, 'B-BRAND'), (16, 21, 'B-TYPE'), (22, 24, 'B-PERCENT')]]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:55:15.722359Z",
     "iopub.status.busy": "2025-10-01T20:55:15.722200Z",
     "iopub.status.idle": "2025-10-01T20:55:15.792569Z",
     "shell.execute_reply": "2025-10-01T20:55:15.792060Z",
     "shell.execute_reply.started": "2025-10-01T20:55:15.722345Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "examples_df = pd.DataFrame({'sample': [x[0] for x in examples], 'annotation': [x[1] for x in examples]})\n",
    "train_texts = train_data['sample'].tolist()\n",
    "examples_df = examples_df[examples_df['sample'].apply(lambda x: x not in train_texts)]\n",
    "examples_df['annotation'] = examples_df['annotation'].astype(str)\n",
    "train_data['is_ad'] = False\n",
    "examples_df['is_ad'] = True\n",
    "train_data = pd.concat([train_data,examples_df],axis=0,ignore_index=True) #.sample(50,random_state=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:55:15.793346Z",
     "iopub.status.busy": "2025-10-01T20:55:15.793166Z",
     "iopub.status.idle": "2025-10-01T20:55:15.820011Z",
     "shell.execute_reply": "2025-10-01T20:55:15.819526Z",
     "shell.execute_reply.started": "2025-10-01T20:55:15.793332Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data['annotation'] = train_data['annotation'].astype(str)\n",
    "train_data['is_percent'] = train_data['annotation'].apply(lambda x: int('PERCENT' in x))\n",
    "train_df, valid_df = train_test_split(train_data, test_size=0.2, random_state=56, shuffle=True, stratify=train_data['is_percent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:55:15.820712Z",
     "iopub.status.busy": "2025-10-01T20:55:15.820532Z",
     "iopub.status.idle": "2025-10-01T20:55:15.824246Z",
     "shell.execute_reply": "2025-10-01T20:55:15.823778Z",
     "shell.execute_reply.started": "2025-10-01T20:55:15.820698Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "valid_df = valid_df[~valid_df['is_ad']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:55:15.825207Z",
     "iopub.status.busy": "2025-10-01T20:55:15.824785Z",
     "iopub.status.idle": "2025-10-01T20:55:15.842525Z",
     "shell.execute_reply": "2025-10-01T20:55:15.842047Z",
     "shell.execute_reply.started": "2025-10-01T20:55:15.825192Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dop_val_samples = [\n",
    "    ('сметана 11', [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT')]),\n",
    "    ('сметана 3', [(0, 7, 'B-TYPE'), (8, 9, 'B-PERCENT')]),\n",
    "    ('сметана 3,4', [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT')]),\n",
    "    ('сметана 10%', [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT')]),\n",
    "    ('сметана 10 %', [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT'), (12, 13, 'I-PERCENT')]),\n",
    "    ('творог 10', [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]),\n",
    "    ('творог 9%', [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]),\n",
    "    ('творог 11 %', [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]),\n",
    "    ('масло сливочное 52', [(0, 5, 'B-TYPE'), (6, 15, 'I-TYPE'), (16, 18, 'B-PERCENT')]),\n",
    "    ('масло сливочное 70%', [(0, 5, 'B-TYPE'), (6, 15, 'I-TYPE'), (16, 19, 'B-PERCENT')]),\n",
    "    ('масло сливочное 74 %', [(0, 5, 'B-TYPE'), (6, 15, 'I-TYPE'), (16, 18, 'B-PERCENT'),  (19, 20, 'I-PERCENT')]),\n",
    "    ('молоко 2,2', [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]),\n",
    "    ('молоко 2,2%', [(0, 6, 'B-TYPE'), (7, 11, 'B-PERCENT')]),\n",
    "    ('молоко 5 %', [(0, 6, 'B-TYPE'), (7, 11, 'B-PERCENT'), (12, 13, 'I-PERCENT')]),\n",
    "    ('молочный коктейль 1', [(0, 8, 'B-TYPE'), (9, 17, 'I-TYPE'), (18, 19, 'B-VOLUME')]),\n",
    "    ('молочный коктейль 1,5', [(0, 8, 'B-TYPE'), (9, 17, 'I-TYPE'), (18, 21, 'B-VOLUME')]),\n",
    "    ('вода 5', [(0, 4, 'B-TYPE'), (5, 6, 'B-VOLUME')]),\t\n",
    "    ('сахар 3', [(0, 5, 'B-TYPE'), (6, 7, 'B-VOLUME')])\n",
    "]\n",
    "\n",
    "examples_df = pd.DataFrame({'sample': [x[0] for x in dop_val_samples], 'annotation': [x[1] for x in dop_val_samples]})\n",
    "train_texts = train_data['sample'].tolist()\n",
    "examples_df = examples_df[examples_df['sample'].apply(lambda x: x not in train_texts)]\n",
    "examples_df['annotation'] = examples_df['annotation'].astype(str)\n",
    "valid_df = pd.concat([valid_df,examples_df],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:55:15.843248Z",
     "iopub.status.busy": "2025-10-01T20:55:15.843076Z",
     "iopub.status.idle": "2025-10-01T20:55:15.881159Z",
     "shell.execute_reply": "2025-10-01T20:55:15.880651Z",
     "shell.execute_reply.started": "2025-10-01T20:55:15.843235Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "valid_ds = Dataset.from_pandas(valid_df, preserve_index=False)\n",
    "raw_datasets = DatasetDict({\"train\": train_ds, \"validation\": valid_ds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:55:15.881936Z",
     "iopub.status.busy": "2025-10-01T20:55:15.881757Z",
     "iopub.status.idle": "2025-10-01T20:55:17.453717Z",
     "shell.execute_reply": "2025-10-01T20:55:17.453172Z",
     "shell.execute_reply.started": "2025-10-01T20:55:15.881922Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db5025950fd84cc9bcb0b72c2a74d9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing and aligning labels:   0%|          | 0/21952 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8717e7da05a547f699e8971fa9f3ad25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing and aligning labels:   0%|          | 0/5502 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ru-en-RoSBERTa\",add_prefix_space=True)\n",
    "\n",
    "def hf_map_fn(examples):\n",
    "    return tokenize_and_align_labels(examples, tokenizer, label2id, label_all_tokens=True, max_length=512)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(\n",
    "    hf_map_fn,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names, \n",
    "    desc=\"Tokenizing and aligning labels\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:55:17.454526Z",
     "iopub.status.busy": "2025-10-01T20:55:17.454306Z",
     "iopub.status.idle": "2025-10-01T20:55:17.534693Z",
     "shell.execute_reply": "2025-10-01T20:55:17.534181Z",
     "shell.execute_reply.started": "2025-10-01T20:55:17.454508Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "valid_samples = valid_df['sample'].tolist()\n",
    "valid_annotation = valid_df['annotation'].apply(eval).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:55:17.535411Z",
     "iopub.status.busy": "2025-10-01T20:55:17.535238Z",
     "iopub.status.idle": "2025-10-01T20:55:17.550640Z",
     "shell.execute_reply": "2025-10-01T20:55:17.550156Z",
     "shell.execute_reply.started": "2025-10-01T20:55:17.535396Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def ner_word_tuples(texts, model, tokenizer, batch_size=16):\n",
    "    single_input = isinstance(texts, str)\n",
    "    texts_list = [texts] if single_input else list(texts)\n",
    "\n",
    "    spans_per_text = []\n",
    "    words_per_text = []\n",
    "    for t in texts_list:\n",
    "        spans = [(m.group(0), m.start(), m.end()) for m in re.finditer(r\"\\S+\", t)]\n",
    "        spans_per_text.append(spans)\n",
    "        words_per_text.append([w for w, _, _ in spans])\n",
    "\n",
    "    if not any(words_per_text):\n",
    "        empty = [[] for _ in texts_list]\n",
    "        return empty[0] if single_input else empty\n",
    "\n",
    "    models = model if isinstance(model, (list, tuple)) else [model]\n",
    "    tokenizers = tokenizer if isinstance(tokenizer, (list, tuple)) else [tokenizer]\n",
    "    if len(models) != len(tokenizers):\n",
    "        raise ValueError(\"models and tokenizers must have the same length\")\n",
    "\n",
    "    label_set = set()\n",
    "    for m in models:\n",
    "        id2label = m.config.id2label\n",
    "        if isinstance(id2label, dict):\n",
    "            for i in range(len(id2label)):\n",
    "                label_set.add(id2label[i])\n",
    "        else:\n",
    "            label_set.update(id2label)\n",
    "    global_labels = (['O'] + sorted([l for l in label_set if l != 'O'])) if 'O' in label_set else sorted(label_set)\n",
    "    label2idx = {lab: i for i, lab in enumerate(global_labels)}\n",
    "\n",
    "    local2global = []\n",
    "    for m in models:\n",
    "        id2label = m.config.id2label\n",
    "        if isinstance(id2label, dict):\n",
    "            local = [label2idx[id2label[i]] for i in range(len(id2label))]\n",
    "        else:\n",
    "            local = [label2idx[l] for l in id2label]\n",
    "        local2global.append(torch.tensor(local, dtype=torch.long))\n",
    "\n",
    "    L = len(global_labels)\n",
    "    O_idx = label2idx.get('O', 0)\n",
    "    o_vec = torch.zeros(L, dtype=torch.float32)\n",
    "    o_vec[O_idx] = 1.0\n",
    "\n",
    "    labels_per_text = [None] * len(texts_list)\n",
    "\n",
    "    for b in range(0, len(texts_list), batch_size):\n",
    "        batch_words = words_per_text[b:b + batch_size]\n",
    "\n",
    "        per_model_word_probs = []\n",
    "        for mi, (m, tok) in enumerate(zip(models, tokenizers)):\n",
    "            enc = tok(\n",
    "                batch_words,\n",
    "                is_split_into_words=True,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "            )\n",
    "            word_ids_list = [enc.word_ids(batch_index=i) for i in range(len(batch_words))]\n",
    "            m_device = next(m.parameters()).device\n",
    "            enc_gpu = {k: v.to(m_device) for k, v in enc.items()}\n",
    "            with torch.inference_mode():\n",
    "                logits = m(**enc_gpu).logits\n",
    "                probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            map_idx = local2global[mi].to(probs.device)\n",
    "            gprobs = torch.zeros(probs.size(0), probs.size(1), L, device=probs.device, dtype=probs.dtype)\n",
    "            gprobs.scatter_add_(dim=-1, index=map_idx.view(1, 1, -1).expand_as(probs), src=probs)\n",
    "            gprobs = gprobs.float().cpu()\n",
    "\n",
    "            model_word_probs = []\n",
    "            for si, wids in enumerate(word_ids_list):\n",
    "                arr = [None] * len(batch_words[si])\n",
    "                gp = gprobs[si]\n",
    "                for ti, wid in enumerate(wids):\n",
    "                    if wid is None:\n",
    "                        continue\n",
    "                    if 0 <= wid < len(arr) and arr[wid] is None:\n",
    "                        arr[wid] = gp[ti]\n",
    "                for wi in range(len(arr)):\n",
    "                    if arr[wi] is None:\n",
    "                        arr[wi] = o_vec\n",
    "                model_word_probs.append(arr)\n",
    "            per_model_word_probs.append(model_word_probs)\n",
    "\n",
    "        for si in range(len(batch_words)):\n",
    "            seq_len = len(batch_words[si])\n",
    "            seq_labels = []\n",
    "            for wi in range(seq_len):\n",
    "                vecs = [per_model_word_probs[mj][si][wi] for mj in range(len(models))]\n",
    "                mean_vec = torch.stack(vecs, dim=0).mean(dim=0)\n",
    "                seq_labels.append(global_labels[int(mean_vec.argmax().item())])\n",
    "            labels_per_text[b + si] = seq_labels\n",
    "\n",
    "    results = []\n",
    "    for i, labs in enumerate(labels_per_text):\n",
    "        labs = _fix_bio(labs)\n",
    "        spans = spans_per_text[i]\n",
    "        results.append([(start, end, lab) for (_, start, end), lab in zip(spans, labs)])\n",
    "\n",
    "    return results[0] if single_input else results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:55:17.551304Z",
     "iopub.status.busy": "2025-10-01T20:55:17.551141Z",
     "iopub.status.idle": "2025-10-01T20:55:17.563736Z",
     "shell.execute_reply": "2025-10-01T20:55:17.563277Z",
     "shell.execute_reply.started": "2025-10-01T20:55:17.551290Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def f1_macro(labels, preds):\n",
    "  ents = {\n",
    "      'TYPE' : [0, 0, 0],\n",
    "      'BRAND' : [0, 0, 0],\n",
    "      'VOLUME' : [0, 0, 0],\n",
    "      'PERCENT' :  [0,0,0]\n",
    "  }\n",
    "  for tr, pr in zip(labels, preds):\n",
    "    ents_cur = {\n",
    "      'TYPE' : [0, 0, 0],\n",
    "      'BRAND' : [0, 0, 0],\n",
    "      'VOLUME' : [0, 0, 0],\n",
    "      'O' : [0,0,0],\n",
    "      'PERCENT' :  [0,0,0]\n",
    "    }\n",
    "    used = []\n",
    "    for tr_i in tr:\n",
    "      flg = 0\n",
    "      for pr_i in pr:\n",
    "        if pr_i == tr_i:\n",
    "          if sum(ents_cur[tr_i[2].split('-')[-1]]) == 0:\n",
    "            ents_cur[tr_i[2].split('-')[-1]][0] = 1\n",
    "          used.append(tr_i[2].split('-')[-1])\n",
    "          flg = 1\n",
    "          break\n",
    "      if flg == 0:\n",
    "        ents_cur[tr_i[2].split('-')[-1]][2] = 1\n",
    "    for pr_i in pr:\n",
    "      ent = pr_i[2].split('-')[-1]\n",
    "      if ent not in used:\n",
    "        ents_cur[ent][1] = 1\n",
    "    for ent in ['TYPE', 'BRAND', 'VOLUME', 'PERCENT']:\n",
    "      ents[ent][0] += ents_cur[ent][0]\n",
    "      ents[ent][1] += ents_cur[ent][1]\n",
    "      ents[ent][2] += ents_cur[ent][2]\n",
    "  f1s = []\n",
    "  for ent in ['TYPE', 'BRAND', 'VOLUME', 'PERCENT']:\n",
    "    TP = ents[ent][0]\n",
    "    FP = ents[ent][1]\n",
    "    FN = ents[ent][2]\n",
    "    if FP + TP + FN != 0:\n",
    "      if FP + TP == 0 or FN + TP == 0 or TP == 0:\n",
    "        f1s.append(0)\n",
    "      else:\n",
    "        rec = TP / (FP + TP)\n",
    "        pre = TP / (FN + TP)\n",
    "        f1s.append(2*rec*pre/(rec+pre)) \n",
    "  return np.mean(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:55:17.564450Z",
     "iopub.status.busy": "2025-10-01T20:55:17.564269Z",
     "iopub.status.idle": "2025-10-01T20:55:17.576692Z",
     "shell.execute_reply": "2025-10-01T20:55:17.576216Z",
     "shell.execute_reply.started": "2025-10-01T20:55:17.564434Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def _fix_bio(labels):\n",
    "    fixed = []\n",
    "    prev_type = None\n",
    "    inside = False\n",
    "    for lab in labels:\n",
    "        if lab is None or lab == \"O\":\n",
    "            fixed.append(\"O\")\n",
    "            prev_type, inside = None, False\n",
    "            continue\n",
    "\n",
    "        if \"-\" in lab:\n",
    "            prefix, typ = lab.split(\"-\", 1)\n",
    "        else:\n",
    "            prefix, typ = \"B\", lab\n",
    "\n",
    "        if prefix == \"I\" and (not inside or prev_type != typ):\n",
    "            fixed.append(f\"B-{typ}\")\n",
    "            prev_type, inside = typ, True\n",
    "        else:\n",
    "            fixed.append(f\"{prefix}-{typ}\")\n",
    "            inside = prefix in (\"B\", \"I\")\n",
    "            prev_type = typ if inside else None\n",
    "    return fixed\n",
    "\n",
    "def _pieces_per_word(word):\n",
    "    return len(tokenizer(word, add_special_tokens=False)[\"input_ids\"]) or 1\n",
    "\n",
    "def _chunk_words(words, max_pieces):\n",
    "    chunk, cur = [], 0\n",
    "    for w in words:\n",
    "        n = _pieces_per_word(w)\n",
    "        if chunk and cur + n > max_pieces:\n",
    "            yield chunk\n",
    "            chunk, cur = [w], n\n",
    "        else:\n",
    "            chunk.append(w)\n",
    "            cur += n\n",
    "    if chunk:\n",
    "        yield chunk\n",
    "\n",
    "def post_proc(val_predicts):\n",
    "    val_predicts_new = []\n",
    "    for tripls in val_predicts:\n",
    "        row,used = [],[]\n",
    "        for i,j,k in tripls:\n",
    "            if k == 'O':\n",
    "                row.append((i,j,k))\n",
    "                continue\n",
    "            tp = k.split('-')[1]\n",
    "            if tp in used:\n",
    "                row.append((i,j,k.replace('B-','I-')))\n",
    "            else:\n",
    "                row.append((i,j,k.replace('I-','B-')))\n",
    "            used.append(tp)\n",
    "        val_predicts_new.append(row)\n",
    "    return val_predicts_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:55:17.577557Z",
     "iopub.status.busy": "2025-10-01T20:55:17.577242Z",
     "iopub.status.idle": "2025-10-01T20:55:17.588719Z",
     "shell.execute_reply": "2025-10-01T20:55:17.588261Z",
     "shell.execute_reply.started": "2025-10-01T20:55:17.577538Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "def compute_metrics_fn(p):\n",
    "    global epoch\n",
    "    preds, labels = p\n",
    "    preds = np.argmax(preds, axis=2)\n",
    "    true_preds, true_labels = [], []\n",
    "    for pred_seq, lab_seq in zip(preds, labels):\n",
    "        pred_tags, lab_tags = [], []\n",
    "        for p_i, l_i in zip(pred_seq, lab_seq):\n",
    "            if l_i == -100:\n",
    "                continue\n",
    "            pred_tags.append(id2label[p_i])\n",
    "            lab_tags.append(id2label[l_i])\n",
    "        true_preds.append(pred_tags)\n",
    "        true_labels.append(lab_tags)\n",
    "    print(classification_report(true_labels, true_preds))\n",
    "    seq_eval_metrics =  {\n",
    "        \"precision\": precision_score(true_labels, true_preds),\n",
    "        \"recall\":    recall_score(true_labels, true_preds),\n",
    "        \"f1\":        f1_score(true_labels, true_preds, average='macro'),\n",
    "        \"accuracy\":  accuracy_score(true_labels, true_preds),\n",
    "    }\n",
    "    #backup = model.state_dict()\n",
    "    #ema_model.copy_to(model)\n",
    "    val_preds = post_proc(ner_word_tuples(valid_samples, model, tokenizer, batch_size=128))\n",
    "    seq_eval_metrics['f1_word_level'] = f1_macro(valid_annotation,val_preds)\n",
    "\n",
    "    model.save_pretrained(f'../../tmp/ckpt_{epoch}')\n",
    "    epoch += 1\n",
    "    #model.load_state_dict(backup)\n",
    "    return seq_eval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:55:17.589360Z",
     "iopub.status.busy": "2025-10-01T20:55:17.589205Z",
     "iopub.status.idle": "2025-10-01T20:55:18.640566Z",
     "shell.execute_reply": "2025-10-01T20:55:18.639977Z",
     "shell.execute_reply.started": "2025-10-01T20:55:17.589347Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at ai-forever/ru-en-RoSBERTa and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "set_seed(56)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"ai-forever/ru-en-RoSBERTa\",\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:55:18.662102Z",
     "iopub.status.busy": "2025-10-01T20:55:18.661929Z",
     "iopub.status.idle": "2025-10-01T20:55:18.705406Z",
     "shell.execute_reply": "2025-10-01T20:55:18.704889Z",
     "shell.execute_reply.started": "2025-10-01T20:55:18.662088Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"rosberta\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    save_total_limit=1,\n",
    "    num_train_epochs=30,\n",
    "    weight_decay=0.0,\n",
    "    warmup_ratio=0.1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    group_by_length=True,\n",
    "    fp16=False,  \n",
    "    report_to=\"none\",\n",
    "    seed=56\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:55:18.706354Z",
     "iopub.status.busy": "2025-10-01T20:55:18.705998Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4102/968564830.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='603' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 603/2580 11:44 < 38:35, 0.85 it/s, Epoch 7/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Word Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.083700</td>\n",
       "      <td>0.331619</td>\n",
       "      <td>0.880042</td>\n",
       "      <td>0.915064</td>\n",
       "      <td>0.430181</td>\n",
       "      <td>0.879092</td>\n",
       "      <td>0.429517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.290500</td>\n",
       "      <td>0.255522</td>\n",
       "      <td>0.925681</td>\n",
       "      <td>0.953001</td>\n",
       "      <td>0.707558</td>\n",
       "      <td>0.926346</td>\n",
       "      <td>0.708224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.201100</td>\n",
       "      <td>0.232377</td>\n",
       "      <td>0.944528</td>\n",
       "      <td>0.953582</td>\n",
       "      <td>0.893530</td>\n",
       "      <td>0.933263</td>\n",
       "      <td>0.834034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.163700</td>\n",
       "      <td>0.298949</td>\n",
       "      <td>0.922620</td>\n",
       "      <td>0.946901</td>\n",
       "      <td>0.914330</td>\n",
       "      <td>0.924762</td>\n",
       "      <td>0.906732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.114600</td>\n",
       "      <td>0.247918</td>\n",
       "      <td>0.944653</td>\n",
       "      <td>0.964794</td>\n",
       "      <td>0.911674</td>\n",
       "      <td>0.941341</td>\n",
       "      <td>0.877496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.079200</td>\n",
       "      <td>0.280757</td>\n",
       "      <td>0.942686</td>\n",
       "      <td>0.967002</td>\n",
       "      <td>0.908223</td>\n",
       "      <td>0.943875</td>\n",
       "      <td>0.872663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/22 00:03 < 00:04, 2.73 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.86      0.70      0.77      3476\n",
      "     PERCENT       1.00      0.01      0.02       104\n",
      "        TYPE       0.88      0.98      0.93     13599\n",
      "      VOLUME       0.00      0.00      0.00        34\n",
      "\n",
      "   micro avg       0.88      0.92      0.90     17213\n",
      "   macro avg       0.69      0.42      0.43     17213\n",
      "weighted avg       0.88      0.92      0.89     17213\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.92      0.82      0.87      3476\n",
      "     PERCENT       0.77      0.93      0.84       104\n",
      "        TYPE       0.93      0.99      0.96     13599\n",
      "      VOLUME       1.00      0.09      0.16        34\n",
      "\n",
      "   micro avg       0.93      0.95      0.94     17213\n",
      "   macro avg       0.90      0.71      0.71     17213\n",
      "weighted avg       0.93      0.95      0.94     17213\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.90      0.87      0.89      3476\n",
      "     PERCENT       0.89      0.99      0.94       104\n",
      "        TYPE       0.96      0.97      0.96     13599\n",
      "      VOLUME       1.00      0.65      0.79        34\n",
      "\n",
      "   micro avg       0.94      0.95      0.95     17213\n",
      "   macro avg       0.94      0.87      0.89     17213\n",
      "weighted avg       0.94      0.95      0.95     17213\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.95      0.77      0.85      3476\n",
      "     PERCENT       0.95      0.95      0.95       104\n",
      "        TYPE       0.92      0.99      0.95     13599\n",
      "      VOLUME       1.00      0.82      0.90        34\n",
      "\n",
      "   micro avg       0.92      0.95      0.93     17213\n",
      "   macro avg       0.96      0.88      0.91     17213\n",
      "weighted avg       0.92      0.95      0.93     17213\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.92      0.89      0.91      3476\n",
      "     PERCENT       0.90      0.99      0.94       104\n",
      "        TYPE       0.95      0.98      0.97     13599\n",
      "      VOLUME       1.00      0.71      0.83        34\n",
      "\n",
      "   micro avg       0.94      0.96      0.95     17213\n",
      "   macro avg       0.94      0.89      0.91     17213\n",
      "weighted avg       0.94      0.96      0.95     17213\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.93      0.88      0.91      3476\n",
      "     PERCENT       0.91      0.97      0.94       104\n",
      "        TYPE       0.95      0.99      0.97     13599\n",
      "      VOLUME       0.93      0.74      0.82        34\n",
      "\n",
      "   micro avg       0.94      0.97      0.95     17213\n",
      "   macro avg       0.93      0.89      0.91     17213\n",
      "weighted avg       0.94      0.97      0.95     17213\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics_fn,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ru-en-RoSBERTa\",add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_23 = AutoModelForTokenClassification.from_pretrained('../../tmp/ckpt_23').cuda()\n",
    "model_25 = AutoModelForTokenClassification.from_pretrained('../../tmp/ckpt_25').cuda()\n",
    "model_27 = AutoModelForTokenClassification.from_pretrained('../../tmp/ckpt_27').cuda()\n",
    "model_28 = AutoModelForTokenClassification.from_pretrained('../../tmp/ckpt_28').cuda()\n",
    "model_29 = AutoModelForTokenClassification.from_pretrained('../../tmp/ckpt_29').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "st_27 = model_27.state_dict()\n",
    "st_28 = model_28.state_dict()\n",
    "st_29 = model_29.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_state_dict = {}\n",
    "for k in st_27:\n",
    "    new_state_dict[k] = (st_27[k] + st_28[k] + st_29[k]) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(new_state_dict,'rosberta_09481.pth')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaL4",
   "dataSources": [
    {
     "databundleVersionId": 11802066,
     "isSourceIdPinned": false,
     "sourceId": 91496,
     "sourceType": "competition"
    },
    {
     "datasetId": 8347497,
     "sourceId": 13172877,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8373140,
     "sourceId": 13210636,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8384728,
     "sourceId": 13227966,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8386031,
     "sourceId": 13229939,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8386045,
     "sourceId": 13229959,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
