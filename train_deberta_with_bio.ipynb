{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T19:46:03.590124Z",
     "iopub.status.busy": "2025-10-01T19:46:03.589393Z",
     "iopub.status.idle": "2025-10-01T19:46:24.736252Z",
     "shell.execute_reply": "2025-10-01T19:46:24.735567Z",
     "shell.execute_reply.started": "2025-10-01T19:46:03.590101Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install seqeval evaluate -q\n",
    "!pip install transformers -U -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T19:46:24.737629Z",
     "iopub.status.busy": "2025-10-01T19:46:24.737397Z",
     "iopub.status.idle": "2025-10-01T19:46:50.334883Z",
     "shell.execute_reply": "2025-10-01T19:46:50.334264Z",
     "shell.execute_reply.started": "2025-10-01T19:46:24.737608Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 19:46:36.268544: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759347996.439372     196 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759347996.489295     196 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import random\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    DataCollatorForTokenClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:00:18.537751Z",
     "iopub.status.busy": "2025-10-01T20:00:18.537080Z",
     "iopub.status.idle": "2025-10-01T20:00:18.542653Z",
     "shell.execute_reply": "2025-10-01T20:00:18.542105Z",
     "shell.execute_reply.started": "2025-10-01T20:00:18.537728Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Sets the seed for reproducibility across multiple libraries.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed) \n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed) \n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "SEED = 42\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:00:18.659284Z",
     "iopub.status.busy": "2025-10-01T20:00:18.659085Z",
     "iopub.status.idle": "2025-10-01T20:00:19.110062Z",
     "shell.execute_reply": "2025-10-01T20:00:19.109477Z",
     "shell.execute_reply.started": "2025-10-01T20:00:18.659270Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/lct25-x5/train (1).csv',sep=';')\n",
    "sample_sub = pd.read_csv('/kaggle/input/lct25-x5/submission (2).csv', sep=';')\n",
    "train_data['annotation'] = train_data['annotation'].apply(eval)\n",
    "train_data['annotation'] = train_data['annotation'].apply(lambda x: [(y[0],y[1],y[2].replace('0','O')) for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:00:19.111793Z",
     "iopub.status.busy": "2025-10-01T20:00:19.111252Z",
     "iopub.status.idle": "2025-10-01T20:00:19.149442Z",
     "shell.execute_reply": "2025-10-01T20:00:19.148631Z",
     "shell.execute_reply.started": "2025-10-01T20:00:19.111769Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_label_list(entity_types: List[str]) -> List[str]:\n",
    "    labels = ['O']\n",
    "    for ent in entity_types:\n",
    "        labels.append(f'B-{ent}')\n",
    "        labels.append(f'I-{ent}')\n",
    "    return labels\n",
    "\n",
    "entity_types = ['BRAND', 'PERCENT', 'TYPE', 'VOLUME']\n",
    "label_list = build_label_list(entity_types) \n",
    "label2id = {l: i for i, l in enumerate(label_list)}\n",
    "id2label = {i: l for l, i in label2id.items()}\n",
    "train_data['annotation'] = train_data['annotation'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:00:19.150325Z",
     "iopub.status.busy": "2025-10-01T20:00:19.150130Z",
     "iopub.status.idle": "2025-10-01T20:00:19.165518Z",
     "shell.execute_reply": "2025-10-01T20:00:19.164970Z",
     "shell.execute_reply.started": "2025-10-01T20:00:19.150311Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "WORD_RE = re.compile(r\"\\S+\")\n",
    "\n",
    "def strip_bio(lab):\n",
    "    if not lab:\n",
    "        return \"\"\n",
    "    lab = str(lab)\n",
    "    if lab == \"O\":\n",
    "        return \"\"\n",
    "    if lab.startswith((\"B-\", \"I-\")):\n",
    "        return lab[2:]\n",
    "    return lab\n",
    "\n",
    "def normalize_spans(spans):\n",
    "    norm = []\n",
    "    for s, e, lab in spans:\n",
    "        ent = strip_bio(lab)\n",
    "        if ent:\n",
    "            norm.append((int(s), int(e), ent))\n",
    "    return norm\n",
    "\n",
    "def compute_overlap(s1: int, e1: int, s2: int, e2: int) -> int:\n",
    "    return max(0, min(e1, e2) - max(s1, s2))\n",
    "\n",
    "def split_words_with_spans(text: str):\n",
    "    return [(m.group(0), m.start(), m.end()) for m in WORD_RE.finditer(text)]\n",
    "\n",
    "def tokenize_and_align_labels(\n",
    "    examples: Dict[str, List[Any]],\n",
    "    tokenizer,\n",
    "    label2id: Dict[str, int],\n",
    "    label_all_tokens: bool = True,\n",
    "    max_length: int = 256\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    На входе:\n",
    "      - examples['sample']: список текстов\n",
    "      - examples['annotation']: список списков спанов в виде строк \"[ (start, end, label), ... ]\"\n",
    "        (каждый элемент будет разобран через ast.literal_eval)\n",
    "    На выходе:\n",
    "      - tokenized inputs с полем 'labels' (список id меток для каждого токена; -100 для спец. токенов)\n",
    "    \"\"\"\n",
    "    texts = examples[\"sample\"]\n",
    "    batch_spans_raw = examples[\"annotation\"]\n",
    "    batch_spans = [normalize_spans(ast.literal_eval(sp)) for sp in batch_spans_raw]\n",
    "\n",
    "    batch_words = []\n",
    "    batch_word_labels = []\n",
    "\n",
    "    for text, spans in zip(texts, batch_spans):\n",
    "        word_triplets = split_words_with_spans(text)  # [(word, s, e), ...]\n",
    "        words = [w for w, _, _ in word_triplets]\n",
    "        batch_words.append(words)\n",
    "\n",
    "        per_word_labels = []\n",
    "        for _, w_start, w_end in word_triplets:\n",
    "            label = \"O\"\n",
    "            best_ent = None\n",
    "            best_ov = 0\n",
    "\n",
    "            for (s, e, ent_type) in spans:\n",
    "                ov = compute_overlap(s, e, w_start, w_end)\n",
    "                if ov > best_ov:\n",
    "                    best_ov = ov\n",
    "                    best_ent = (s, e, ent_type)\n",
    "\n",
    "            if best_ent is not None and best_ov > 0:\n",
    "                ent_start, ent_end, ent_type = best_ent\n",
    "                if w_start == ent_start:\n",
    "                    label = f\"B-{ent_type}\"\n",
    "                else:\n",
    "                    label = f\"I-{ent_type}\"\n",
    "\n",
    "            per_word_labels.append(label)\n",
    "\n",
    "        batch_word_labels.append(per_word_labels)\n",
    "\n",
    "    tokenized = tokenizer(\n",
    "        batch_words,\n",
    "        is_split_into_words=True,\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=max_length,\n",
    "        return_tensors=None \n",
    "    )\n",
    "\n",
    "    all_labels: List[List[int]] = []\n",
    "\n",
    "    for i in range(len(batch_words)):\n",
    "        word_ids = tokenized.word_ids(batch_index=i)  # список индексов слов для каждого токена\n",
    "        if word_ids is None:\n",
    "            raise ValueError(\"Tokenizer must be a fast tokenizer to use word_ids.\")\n",
    "\n",
    "        labels_ids: List[int] = []\n",
    "        prev_word_id = None\n",
    "        per_word = batch_word_labels[i]\n",
    "\n",
    "        for w_id in word_ids:\n",
    "            if w_id is None:\n",
    "                labels_ids.append(-100)  # спец. токены\n",
    "            else:\n",
    "                label_str = per_word[w_id]\n",
    "                if not label_all_tokens and w_id == prev_word_id:\n",
    "                    labels_ids.append(-100)  # только первый сабтокен помечаем\n",
    "                else:\n",
    "                    labels_ids.append(label2id[label_str])\n",
    "            prev_word_id = w_id\n",
    "\n",
    "        all_labels.append(labels_ids)\n",
    "\n",
    "    tokenized[\"labels\"] = all_labels\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:00:20.819255Z",
     "iopub.status.busy": "2025-10-01T20:00:20.818751Z",
     "iopub.status.idle": "2025-10-01T20:00:20.871468Z",
     "shell.execute_reply": "2025-10-01T20:00:20.870940Z",
     "shell.execute_reply.started": "2025-10-01T20:00:20.819233Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "examples = [\n",
    "    [\"йогурт 2%\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"йогурт 2,5\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"йогурт питьевой 1.5%\", [(0, 6, 'B-TYPE'), (7, 15, 'I-TYPE'), (16, 20, 'B-PERCENT')]],\n",
    "    [\"ряженка 4 %\", [(0, 7, 'B-TYPE'), (8, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]],\n",
    "    [\"ряженка 4%\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT')]],\n",
    "    [\"кефир 2.5%\", [(0, 5, 'B-TYPE'), (6, 10, 'B-PERCENT')]],\n",
    "    [\"кефир 0%\", [(0, 5, 'B-TYPE'), (6, 8, 'B-PERCENT')]],\n",
    "    [\"кефир бифидум 1\", [(0, 5, 'B-TYPE'), (6, 13, 'I-TYPE'), (14, 15, 'B-PERCENT')]],\n",
    "    [\"молоко 2 %\", [(0, 6, 'B-TYPE'), (7, 8, 'B-PERCENT'), (9, 10, 'I-PERCENT')]],\n",
    "    [\"молоко 2.5\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"молоко пастеризованное 3,2%\", [(0, 6, 'B-TYPE'), (7, 22, 'I-TYPE'), (23, 27, 'B-PERCENT')]],\n",
    "    [\"творог мягкий 0.5%\", [(0, 6, 'B-TYPE'), (7, 13, 'I-TYPE'), (14, 18, 'B-PERCENT')]],\n",
    "    [\"творог 18%\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"творог зерненый 5\", [(0, 6, 'B-TYPE'), (7, 15, 'I-TYPE'), (16, 17, 'B-PERCENT')]],\n",
    "    [\"сметана 30%\", [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT')]],\n",
    "    [\"сметана 30\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT')]],\n",
    "    [\"сметана фермерская 25 %\", [(0, 7, 'B-TYPE'), (8, 18, 'I-TYPE'), (19, 21, 'B-PERCENT'), (22, 23, 'I-PERCENT')]],\n",
    "    [\"сыр плавленый 45%\", [(0, 3, 'B-TYPE'), (4, 13, 'I-TYPE'), (14, 17, 'B-PERCENT')]],\n",
    "    [\"сыр твердый 50\", [(0, 3, 'B-TYPE'), (4, 11, 'I-TYPE'), (12, 14, 'B-PERCENT')]],\n",
    "    [\"сыр 45 %\", [(0, 3, 'B-TYPE'), (4, 6, 'B-PERCENT'), (7, 8, 'I-PERCENT')]],\n",
    "    [\"масло сливочное 62%\", [(0, 5, 'B-TYPE'), (6, 15, 'I-TYPE'), (16, 19, 'B-PERCENT')]],\n",
    "    [\"масло 72.5\", [(0, 5, 'B-TYPE'), (6, 10, 'B-PERCENT')]],\n",
    "    [\"масло топленое 99\", [(0, 5, 'B-TYPE'), (6, 14, 'I-TYPE'), (15, 17, 'B-PERCENT')]],\n",
    "    [\"сливки 15%\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"сливки 15\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"сливки взбитые 35 %\", [(0, 6, 'B-TYPE'), (7, 14, 'I-TYPE'), (15, 17, 'B-PERCENT'), (18, 19, 'I-PERCENT')]],\n",
    "    [\"простоквашино молоко 3.2\", [(0, 13, 'B-BRAND'), (14, 20, 'B-TYPE'), (21, 24, 'B-PERCENT')]],\n",
    "    [\"домик в деревне кефир 1%\", [(0, 15, 'B-BRAND'), (16, 21, 'B-TYPE'), (22, 24, 'B-PERCENT')]],\n",
    "    [\"йогурт греческий 0\", [(0, 6, 'B-TYPE'), (7, 16, 'I-TYPE'), (17, 18, 'B-PERCENT')]],\n",
    "    [\"ряженка 2.5%\", [(0, 7, 'B-TYPE'), (8, 12, 'B-PERCENT')]],\n",
    "    [\"кефир 3,2\", [(0, 5, 'B-TYPE'), (6, 9, 'B-PERCENT')]],\n",
    "    [\"молоко 0.5 %\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT'), (11, 12, 'I-PERCENT')]],\n",
    "    [\"творог 0%\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"сметана 18 %\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT'), (11, 12, 'I-PERCENT')]],\n",
    "    [\"сыр мягкий 20%\", [(0, 3, 'B-TYPE'), (4, 10, 'I-TYPE'), (11, 14, 'B-PERCENT')]],\n",
    "    [\"масло растительное 100%\", [(0, 5, 'B-TYPE'), (6, 18, 'I-TYPE'), (19, 23, 'B-PERCENT')]],\n",
    "    [\"сливки 25%\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"йогурт 1.5\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"ряженка 3 %\", [(0, 7, 'B-TYPE'), (8, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]],\n",
    "    [\"кефир обезжиренный 0\", [(0, 5, 'B-TYPE'), (6, 18, 'I-TYPE'), (19, 20, 'B-PERCENT')]],\n",
    "    [\"молоко 4%\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"творог 2 %\", [(0, 6, 'B-TYPE'), (7, 8, 'B-PERCENT'), (9, 10, 'I-PERCENT')]],\n",
    "    [\"сметана 12%\", [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT')]],\n",
    "    [\"сыр 55\", [(0, 3, 'B-TYPE'), (4, 6, 'B-PERCENT')]],\n",
    "    [\"масло 82.5%\", [(0, 5, 'B-TYPE'), (6, 11, 'B-PERCENT')]],\n",
    "    [\"сливки 40\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"йогурт 3.2 %\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT'), (11, 12, 'I-PERCENT')]],\n",
    "    [\"ряженка 1%\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT')]],\n",
    "    [\"кефир 2 %\", [(0, 5, 'B-TYPE'), (6, 7, 'B-PERCENT'), (8, 9, 'I-PERCENT')]],\n",
    "    [\"молоко топленое 4\", [(0, 6, 'B-TYPE'), (7, 15, 'I-TYPE'), (16, 17, 'B-PERCENT')]],\n",
    "    [\"творог 15%\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"сметана 35\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT')]],\n",
    "    [\"сыр с плесенью 50%\", [(0, 3, 'B-TYPE'), (4, 14, 'I-TYPE'), (15, 18, 'B-PERCENT')]],\n",
    "    [\"масло кокосовое 99%\", [(0, 5, 'B-TYPE'), (6, 15, 'I-TYPE'), (16, 19, 'B-PERCENT')]],\n",
    "    [\"сливки 12 %\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]],\n",
    "    [\"йогурт натуральный 2.5\", [(0, 6, 'B-TYPE'), (7, 18, 'I-TYPE'), (19, 22, 'B-PERCENT')]],\n",
    "    [\"ряженка 0.5%\", [(0, 7, 'B-TYPE'), (8, 12, 'B-PERCENT')]],\n",
    "    [\"кефир 4%\", [(0, 5, 'B-TYPE'), (6, 8, 'B-PERCENT')]],\n",
    "    [\"молоко 1.5%\", [(0, 6, 'B-TYPE'), (7, 11, 'B-PERCENT')]],\n",
    "    [\"творог обезжиренный 0 %\", [(0, 6, 'B-TYPE'), (7, 19, 'I-TYPE'), (20, 21, 'B-PERCENT'), (22, 23, 'I-PERCENT')]],\n",
    "    [\"сметана 40%\", [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT')]],\n",
    "    [\"сыр 60 %\", [(0, 3, 'B-TYPE'), (4, 6, 'B-PERCENT'), (7, 8, 'I-PERCENT')]],\n",
    "    [\"масло 90\", [(0, 5, 'B-TYPE'), (6, 8, 'B-PERCENT')]],\n",
    "    [\"сливки стерилизованные 10\", [(0, 6, 'B-TYPE'), (7, 23, 'I-TYPE'), (24, 26, 'B-PERCENT')]],\n",
    "    [\"йогурт 0 %\", [(0, 6, 'B-TYPE'), (7, 8, 'B-PERCENT'), (9, 10, 'I-PERCENT')]],\n",
    "    [\"ряженка 5\", [(0, 7, 'B-TYPE'), (8, 9, 'B-PERCENT')]],\n",
    "    [\"кефир фруктовый 1.5 %\", [(0, 5, 'B-TYPE'), (6, 15, 'I-TYPE'), (16, 19, 'B-PERCENT'), (20, 21, 'I-PERCENT')]],\n",
    "    [\"молоко 3%\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"творог 3.5\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"сметана домашняя 20\", [(0, 7, 'B-TYPE'), (8, 16, 'I-TYPE'), (17, 19, 'B-PERCENT')]],\n",
    "    [\"сыр кремовый 30%\", [(0, 3, 'B-TYPE'), (4, 12, 'I-TYPE'), (13, 16, 'B-PERCENT')]],\n",
    "    [\"масло 75 %\", [(0, 5, 'B-TYPE'), (6, 8, 'B-PERCENT'), (9, 10, 'I-PERCENT')]],\n",
    "    [\"сливки 18%\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"йогурт 4 %\", [(0, 6, 'B-TYPE'), (7, 8, 'B-PERCENT'), (9, 10, 'I-PERCENT')]],\n",
    "    [\"ряженка 2%\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT')]],\n",
    "    [\"кефир 0.1%\", [(0, 5, 'B-TYPE'), (6, 10, 'B-PERCENT')]],\n",
    "    [\"молоко цельное 3.5 %\", [(0, 6, 'B-TYPE'), (7, 14, 'I-TYPE'), (15, 18, 'B-PERCENT'), (19, 20, 'I-PERCENT')]],\n",
    "    [\"творог 12\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"сметана 22%\", [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT')]],\n",
    "    [\"сыр 40\", [(0, 3, 'B-TYPE'), (4, 6, 'B-PERCENT')]],\n",
    "    [\"масло сливочное 80\", [(0, 5, 'B-TYPE'), (6, 15, 'I-TYPE'), (16, 18, 'B-PERCENT')]],\n",
    "    [\"сливки 22 %\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]],\n",
    "    [\"йогурт обезжиренный 0\", [(0, 6, 'B-TYPE'), (7, 19, 'I-TYPE'), (20, 21, 'B-PERCENT')]],\n",
    "    [\"ряженка 3.2\", [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT')]],\n",
    "    [\"кефир 2.0 %\", [(0, 5, 'B-TYPE'), (6, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]],\n",
    "    [\"молоко 2.0\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"творог классический 9%\", [(0, 6, 'B-TYPE'), (7, 19, 'I-TYPE'), (20, 22, 'B-PERCENT')]],\n",
    "    [\"сметана 28\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT')]],\n",
    "    [\"сыр пармезан 32%\", [(0, 3, 'B-TYPE'), (4, 12, 'I-TYPE'), (13, 16, 'B-PERCENT')]],\n",
    "    [\"масло 85%\", [(0, 5, 'B-TYPE'), (6, 9, 'B-PERCENT')]],\n",
    "    [\"сливки 28\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"йогурт 5%\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"ряженка 4.0 %\", [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT'), (12, 13, 'I-PERCENT')]],\n",
    "    [\"кефир 3%\", [(0, 5, 'B-TYPE'), (6, 8, 'B-PERCENT')]],\n",
    "    [\"молоко 0%\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"творог 4%\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"сметана 15\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT')]],\n",
    "    [\"сыр чеддер 48%\", [(0, 3, 'B-TYPE'), (4, 10, 'I-TYPE'), (11, 14, 'B-PERCENT')]],\n",
    "    [\"масло топленое 98 %\", [(0, 5, 'B-TYPE'), (6, 14, 'I-TYPE'), (15, 17, 'B-PERCENT'), (18, 19, 'I-PERCENT')]],\n",
    "    [\"сливки 35%\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"йогурт 2.0%\", [(0, 6, 'B-TYPE'), (7, 11, 'B-PERCENT')]],\n",
    "    [\"ряженка 1.5\", [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT')]],\n",
    "    [\"кефир 1.0\", [(0, 5, 'B-TYPE'), (6, 9, 'B-PERCENT')]],\n",
    "    [\"молоко ультрапастеризованное 1%\", [(0, 6, 'B-TYPE'), (7, 28, 'I-TYPE'), (29, 31, 'B-PERCENT')]],\n",
    "    [\"творог 6 %\", [(0, 6, 'B-TYPE'), (7, 8, 'B-PERCENT'), (9, 10, 'I-PERCENT')]],\n",
    "    [\"сметана 10 %\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT'), (11, 12, 'I-PERCENT')]],\n",
    "    [\"сыр легкий 10\", [(0, 3, 'B-TYPE'), (4, 10, 'I-TYPE'), (11, 13, 'B-PERCENT')]],\n",
    "    [\"масло сливочное 70%\", [(0, 5, 'B-TYPE'), (6, 15, 'I-TYPE'), (16, 19, 'B-PERCENT')]],\n",
    "    [\"сливки 30 %\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]],\n",
    "    [\"йогурт 3%\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"ряженка 2.0%\", [(0, 7, 'B-TYPE'), (8, 12, 'B-PERCENT')]],\n",
    "    [\"кефир 0 %\", [(0, 5, 'B-TYPE'), (6, 7, 'B-PERCENT'), (8, 9, 'I-PERCENT')]],\n",
    "    [\"молоко 4.5\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"творог мягкий 2%\", [(0, 6, 'B-TYPE'), (7, 13, 'I-TYPE'), (14, 16, 'B-PERCENT')]],\n",
    "    [\"сметана 25%\", [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT')]],\n",
    "    [\"сыр 25 %\", [(0, 3, 'B-TYPE'), (4, 6, 'B-PERCENT'), (7, 8, 'I-PERCENT')]],\n",
    "    [\"масло 60\", [(0, 5, 'B-TYPE'), (6, 8, 'B-PERCENT')]],\n",
    "    [\"сливки 5%\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"йогурт питьевой 0.5 %\", [(0, 6, 'B-TYPE'), (7, 15, 'I-TYPE'), (16, 19, 'B-PERCENT'), (20, 21, 'I-PERCENT')]],\n",
    "    [\"ряженка 3%\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT')]],\n",
    "    [\"кефир 2.5\", [(0, 5, 'B-TYPE'), (6, 9, 'B-PERCENT')]],\n",
    "    [\"молоко 3.5%\", [(0, 6, 'B-TYPE'), (7, 11, 'B-PERCENT')]],\n",
    "    [\"творог 7\", [(0, 6, 'B-TYPE'), (7, 8, 'B-PERCENT')]],\n",
    "    [\"сметана 5 %\", [(0, 7, 'B-TYPE'), (8, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]],\n",
    "    [\"сыр твердый 45 %\", [(0, 3, 'B-TYPE'), (4, 11, 'I-TYPE'), (12, 14, 'B-PERCENT'), (15, 16, 'I-PERCENT')]],\n",
    "    [\"масло 72 %\", [(0, 5, 'B-TYPE'), (6, 8, 'B-PERCENT'), (9, 10, 'I-PERCENT')]],\n",
    "    [\"сливки 40%\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"йогурт 1 %\", [(0, 6, 'B-TYPE'), (7, 8, 'B-PERCENT'), (9, 10, 'I-PERCENT')]],\n",
    "    [\"ряженка 0%\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT')]],\n",
    "    [\"кефир 3.5 %\", [(0, 5, 'B-TYPE'), (6, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]],\n",
    "    [\"молоко 2.5 %\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT'), (11, 12, 'I-PERCENT')]],\n",
    "    [\"творог 10%\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"сметана 30 %\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT'), (11, 12, 'I-PERCENT')]],\n",
    "    [\"сыр 35\", [(0, 3, 'B-TYPE'), (4, 6, 'B-PERCENT')]],\n",
    "    [\"масло сливочное 85 %\", [(0, 5, 'B-TYPE'), (6, 15, 'I-TYPE'), (16, 18, 'B-PERCENT'), (19, 20, 'I-PERCENT')]],\n",
    "    [\"сливки 15 %\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]],\n",
    "    [\"йогурт 4.5\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"ряженка 5%\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT')]],\n",
    "    [\"кефир 1.5\", [(0, 5, 'B-TYPE'), (6, 9, 'B-PERCENT')]],\n",
    "    [\"молоко 1\", [(0, 6, 'B-TYPE'), (7, 8, 'B-PERCENT')]],\n",
    "    [\"творог 0.5 %\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT'), (11, 12, 'I-PERCENT')]],\n",
    "    [\"сметана 18%\", [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT')]],\n",
    "    [\"сыр легкий 20 %\", [(0, 3, 'B-TYPE'), (4, 10, 'I-TYPE'), (11, 13, 'B-PERCENT'), (14, 15, 'I-PERCENT')]],\n",
    "    [\"масло 82\", [(0, 5, 'B-TYPE'), (6, 8, 'B-PERCENT')]],\n",
    "    [\"сливки 20 %\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]],\n",
    "    [\"йогурт 2.5 %\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT'), (11, 12, 'I-PERCENT')]],\n",
    "    [\"ряженка 4 %\", [(0, 7, 'B-TYPE'), (8, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]],\n",
    "    [\"кефир 0.5\", [(0, 5, 'B-TYPE'), (6, 9, 'B-PERCENT')]],\n",
    "    [\"молоко 3.2 %\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT'), (11, 12, 'I-PERCENT')]],\n",
    "    [\"творог 5 %\", [(0, 6, 'B-TYPE'), (7, 8, 'B-PERCENT'), (9, 10, 'I-PERCENT')]],\n",
    "    [\"сметана 20 %\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT'), (11, 12, 'I-PERCENT')]],\n",
    "    [\"сыр 50%\", [(0, 3, 'B-TYPE'), (4, 7, 'B-PERCENT')]],\n",
    "    [\"масло сливочное 72 %\", [(0, 5, 'B-TYPE'), (6, 15, 'I-TYPE'), (16, 18, 'B-PERCENT'), (19, 20, 'I-PERCENT')]],\n",
    "    [\"сливки 33\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"йогурт 0.1%\", [(0, 6, 'B-TYPE'), (7, 11, 'B-PERCENT')]],\n",
    "    [\"ряженка 2.5 %\", [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT'), (12, 13, 'I-PERCENT')]],\n",
    "    [\"кефир 2%\", [(0, 5, 'B-TYPE'), (6, 8, 'B-PERCENT')]],\n",
    "    [\"молоко 0.5\", [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]],\n",
    "    [\"творог 9%\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"сметана 25 %\", [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT'), (11, 12, 'I-PERCENT')]],\n",
    "    [\"сыр 15%\", [(0, 3, 'B-TYPE'), (4, 7, 'B-PERCENT')]],\n",
    "    [\"масло 80 %\", [(0, 5, 'B-TYPE'), (6, 8, 'B-PERCENT'), (9, 10, 'I-PERCENT')]],\n",
    "    [\"сливки 10\", [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]],\n",
    "    [\"балтика 1\", [(0, 7, 'B-BRAND'), (8, 9, 'B-PERCENT')]],\n",
    "    [\"нестожен молоко 2\", [(0, 8, 'B-BRAND'), (9, 15, 'B-TYPE'), (16, 17, 'B-PERCENT')]],\n",
    "    [\"простоквашино сметана 15%\", [(0, 13, 'B-BRAND'), (14, 21, 'B-TYPE'), (22, 25, 'B-PERCENT')]],\n",
    "    [\"домик в деревне творог 5\", [(0, 15, 'B-BRAND'), (16, 22, 'B-TYPE'), (23, 24, 'B-PERCENT')]],\n",
    "    [\"балтика кефир 0%\", [(0, 7, 'B-BRAND'), (8, 13, 'B-TYPE'), (14, 16, 'B-PERCENT')]],\n",
    "    [\"нестожен йогурт 1.5\", [(0, 8, 'B-BRAND'), (9, 15, 'B-TYPE'), (16, 19, 'B-PERCENT')]],\n",
    "    [\"простоквашино сливки 20 %\", [(0, 13, 'B-BRAND'), (14, 20, 'B-TYPE'), (21, 23, 'B-PERCENT'), (24, 25, 'I-PERCENT')]],\n",
    "    [\"домик в деревне сыр 45\", [(0, 15, 'B-BRAND'), (16, 19, 'B-TYPE'), (20, 22, 'B-PERCENT')]],\n",
    "    [\"балтика ряженка 3,2\", [(0, 7, 'B-BRAND'), (8, 15, 'B-TYPE'), (16, 19, 'B-PERCENT')]],\n",
    "    [\"нестожен масло 82%\", [(0, 8, 'B-BRAND'), (9, 14, 'B-TYPE'), (15, 18, 'B-PERCENT')]],\n",
    "    [\"простоквашино творог 9 %\", [(0, 13, 'B-BRAND'), (14, 20, 'B-TYPE'), (21, 22, 'B-PERCENT'), (23, 24, 'I-PERCENT')]],\n",
    "    [\"домик в деревне молоко 3.2%\", [(0, 15, 'B-BRAND'), (16, 22, 'B-TYPE'), (23, 27, 'B-PERCENT')]],\n",
    "    [\"балтика сметана 10\", [(0, 7, 'B-BRAND'), (8, 15, 'B-TYPE'), (16, 18, 'B-PERCENT')]],\n",
    "    [\"нестожен кефир 2.5 %\", [(0, 8, 'B-BRAND'), (9, 14, 'B-TYPE'), (15, 18, 'B-PERCENT'), (19, 20, 'I-PERCENT')]],\n",
    "    [\"простоквашино йогурт 0\", [(0, 13, 'B-BRAND'), (14, 20, 'B-TYPE'), (21, 22, 'B-PERCENT')]],\n",
    "    [\"домик в деревне сливки 33%\", [(0, 15, 'B-BRAND'), (16, 22, 'B-TYPE'), (23, 26, 'B-PERCENT')]],\n",
    "    [\"балтика сыр легкий 15\", [(0, 7, 'B-BRAND'), (8, 11, 'B-TYPE'), (12, 18, 'I-TYPE'), (19, 21, 'B-PERCENT')]],\n",
    "    [\"нестожен ряженка 4%\", [(0, 8, 'B-BRAND'), (9, 16, 'B-TYPE'), (17, 19, 'B-PERCENT')]],\n",
    "    [\"простоквашино масло сливочное 72\", [(0, 13, 'B-BRAND'), (14, 19, 'B-TYPE'), (20, 29, 'I-TYPE'), (30, 32, 'B-PERCENT')]],\n",
    "    [\"домик в деревне сметана 20%\", [(0, 15, 'B-BRAND'), (16, 23, 'B-TYPE'), (24, 27, 'B-PERCENT')]],\n",
    "    [\"балтика молоко 1 %\", [(0, 7, 'B-BRAND'), (8, 14, 'B-TYPE'), (15, 16, 'B-PERCENT'), (17, 18, 'I-PERCENT')]],\n",
    "    [\"нестожен творог 5\", [(0, 8, 'B-BRAND'), (9, 15, 'B-TYPE'), (16, 17, 'B-PERCENT')]],\n",
    "    [\"простоквашино кефир 1\", [(0, 13, 'B-BRAND'), (14, 19, 'B-TYPE'), (20, 21, 'B-PERCENT')]],\n",
    "    [\"домик в деревне йогурт 2.5\", [(0, 15, 'B-BRAND'), (16, 22, 'B-TYPE'), (23, 26, 'B-PERCENT')]],\n",
    "    [\"балтика сливки 10%\", [(0, 7, 'B-BRAND'), (8, 14, 'B-TYPE'), (15, 18, 'B-PERCENT')]],\n",
    "    [\"нестожен сыр 45 %\", [(0, 8, 'B-BRAND'), (9, 12, 'B-TYPE'), (13, 15, 'B-PERCENT'), (16, 17, 'I-PERCENT')]],\n",
    "    [\"простоквашино ряженка 3.2\", [(0, 13, 'B-BRAND'), (14, 21, 'B-TYPE'), (22, 25, 'B-PERCENT')]],\n",
    "    [\"домик в деревне масло 82\", [(0, 15, 'B-BRAND'), (16, 21, 'B-TYPE'), (22, 24, 'B-PERCENT')]]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:00:23.647172Z",
     "iopub.status.busy": "2025-10-01T20:00:23.646552Z",
     "iopub.status.idle": "2025-10-01T20:00:23.717993Z",
     "shell.execute_reply": "2025-10-01T20:00:23.717467Z",
     "shell.execute_reply.started": "2025-10-01T20:00:23.647152Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "examples_df = pd.DataFrame({'sample': [x[0] for x in examples], 'annotation': [x[1] for x in examples]})\n",
    "train_texts = train_data['sample'].tolist()\n",
    "examples_df = examples_df[examples_df['sample'].apply(lambda x: x not in train_texts)]\n",
    "examples_df['annotation'] = examples_df['annotation'].astype(str)\n",
    "train_data['is_ad'] = False\n",
    "examples_df['is_ad'] = True\n",
    "train_data = pd.concat([train_data,examples_df],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:00:26.508270Z",
     "iopub.status.busy": "2025-10-01T20:00:26.507647Z",
     "iopub.status.idle": "2025-10-01T20:00:26.540354Z",
     "shell.execute_reply": "2025-10-01T20:00:26.539825Z",
     "shell.execute_reply.started": "2025-10-01T20:00:26.508251Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "set_seed(SEED)\n",
    "train_data['annotation'] = train_data['annotation'].astype(str)\n",
    "train_data['is_percent'] = train_data['annotation'].apply(lambda x: int('PERCENT' in x))\n",
    "train_df, valid_df = train_test_split(train_data, test_size=0.2, random_state=56, shuffle=True, stratify=train_data['is_percent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:00:27.605856Z",
     "iopub.status.busy": "2025-10-01T20:00:27.605219Z",
     "iopub.status.idle": "2025-10-01T20:00:27.610515Z",
     "shell.execute_reply": "2025-10-01T20:00:27.610001Z",
     "shell.execute_reply.started": "2025-10-01T20:00:27.605827Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "valid_df = valid_df[~valid_df['is_ad']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:00:30.643398Z",
     "iopub.status.busy": "2025-10-01T20:00:30.642775Z",
     "iopub.status.idle": "2025-10-01T20:00:30.661998Z",
     "shell.execute_reply": "2025-10-01T20:00:30.661276Z",
     "shell.execute_reply.started": "2025-10-01T20:00:30.643378Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dop_val_samples = [\n",
    "    ('сметана 11', [(0, 7, 'B-TYPE'), (8, 10, 'B-PERCENT')]),\n",
    "    ('сметана 3', [(0, 7, 'B-TYPE'), (8, 9, 'B-PERCENT')]),\n",
    "    ('сметана 3,4', [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT')]),\n",
    "    ('сметана 10%', [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT')]),\n",
    "    ('сметана 10 %', [(0, 7, 'B-TYPE'), (8, 11, 'B-PERCENT'), (12, 13, 'I-PERCENT')]),\n",
    "    ('творог 10', [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]),\n",
    "    ('творог 9%', [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT')]),\n",
    "    ('творог 11 %', [(0, 6, 'B-TYPE'), (7, 9, 'B-PERCENT'), (10, 11, 'I-PERCENT')]),\n",
    "    ('масло сливочное 52', [(0, 5, 'B-TYPE'), (6, 15, 'I-TYPE'), (16, 18, 'B-PERCENT')]),\n",
    "    ('масло сливочное 70%', [(0, 5, 'B-TYPE'), (6, 15, 'I-TYPE'), (16, 19, 'B-PERCENT')]),\n",
    "    ('масло сливочное 74 %', [(0, 5, 'B-TYPE'), (6, 15, 'I-TYPE'), (16, 18, 'B-PERCENT'),  (19, 20, 'I-PERCENT')]),\n",
    "    ('молоко 2,2', [(0, 6, 'B-TYPE'), (7, 10, 'B-PERCENT')]),\n",
    "    ('молоко 2,2%', [(0, 6, 'B-TYPE'), (7, 11, 'B-PERCENT')]),\n",
    "    ('молоко 5 %', [(0, 6, 'B-TYPE'), (7, 11, 'B-PERCENT'), (12, 13, 'I-PERCENT')]),\n",
    "    ('молочный коктейль 1', [(0, 8, 'B-TYPE'), (9, 17, 'I-TYPE'), (18, 19, 'B-VOLUME')]),\n",
    "    ('молочный коктейль 1,5', [(0, 8, 'B-TYPE'), (9, 17, 'I-TYPE'), (18, 21, 'B-VOLUME')]),\n",
    "    ('вода 5', [(0, 4, 'B-TYPE'), (5, 6, 'B-VOLUME')]),\t\n",
    "    ('сахар 3', [(0, 5, 'B-TYPE'), (6, 7, 'B-VOLUME')])\n",
    "]\n",
    "\n",
    "examples_df = pd.DataFrame({'sample': [x[0] for x in dop_val_samples], 'annotation': [x[1] for x in dop_val_samples]})\n",
    "train_texts = train_data['sample'].tolist()\n",
    "examples_df = examples_df[examples_df['sample'].apply(lambda x: x not in train_texts)]\n",
    "examples_df['annotation'] = examples_df['annotation'].astype(str)\n",
    "valid_df = pd.concat([valid_df,examples_df],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:01:26.167021Z",
     "iopub.status.busy": "2025-10-01T20:01:26.166342Z",
     "iopub.status.idle": "2025-10-01T20:01:26.206387Z",
     "shell.execute_reply": "2025-10-01T20:01:26.205845Z",
     "shell.execute_reply.started": "2025-10-01T20:01:26.167001Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "valid_ds = Dataset.from_pandas(valid_df, preserve_index=False)\n",
    "raw_datasets = DatasetDict({\"train\": train_ds, \"validation\": valid_ds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:01:29.779904Z",
     "iopub.status.busy": "2025-10-01T20:01:29.779365Z",
     "iopub.status.idle": "2025-10-01T20:01:35.988213Z",
     "shell.execute_reply": "2025-10-01T20:01:35.987460Z",
     "shell.execute_reply.started": "2025-10-01T20:01:29.779881Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98986038fd304c668bc15918662d483f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing and aligning labels:   0%|          | 0/26439 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0856075efde42f3b75dd42cd513996c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing and aligning labels:   0%|          | 0/5465 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/mdeberta-v3-base\")\n",
    "\n",
    "def hf_map_fn(examples):\n",
    "    return tokenize_and_align_labels(examples, tokenizer, label2id, label_all_tokens=True, max_length=512)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(\n",
    "    hf_map_fn,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names, \n",
    "    desc=\"Tokenizing and aligning labels\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:01:35.989313Z",
     "iopub.status.busy": "2025-10-01T20:01:35.989123Z",
     "iopub.status.idle": "2025-10-01T20:01:36.070457Z",
     "shell.execute_reply": "2025-10-01T20:01:36.069959Z",
     "shell.execute_reply.started": "2025-10-01T20:01:35.989299Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "valid_samples = valid_df['sample'].tolist()\n",
    "valid_annotation = valid_df['annotation'].apply(eval).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:01:36.071350Z",
     "iopub.status.busy": "2025-10-01T20:01:36.071174Z",
     "iopub.status.idle": "2025-10-01T20:01:36.086409Z",
     "shell.execute_reply": "2025-10-01T20:01:36.085863Z",
     "shell.execute_reply.started": "2025-10-01T20:01:36.071336Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "\n",
    "def ner_word_tuples(texts, model, tokenizer, batch_size=16):\n",
    "    single_input = isinstance(texts, str)\n",
    "    texts_list = [texts] if single_input else list(texts)\n",
    "\n",
    "    spans_per_text = []\n",
    "    words_per_text = []\n",
    "    for t in texts_list:\n",
    "        spans = [(m.group(0), m.start(), m.end()) for m in re.finditer(r\"\\S+\", t)]\n",
    "        spans_per_text.append(spans)\n",
    "        words_per_text.append([w for w, _, _ in spans])\n",
    "\n",
    "    if not any(words_per_text):\n",
    "        empty = [[] for _ in texts_list]\n",
    "        return empty[0] if single_input else empty\n",
    "\n",
    "    models = model if isinstance(model, (list, tuple)) else [model]\n",
    "    tokenizers = tokenizer if isinstance(tokenizer, (list, tuple)) else [tokenizer]\n",
    "    if len(models) != len(tokenizers):\n",
    "        raise ValueError(\"models and tokenizers must have the same length\")\n",
    "\n",
    "    label_set = set()\n",
    "    for m in models:\n",
    "        id2label = m.config.id2label\n",
    "        if isinstance(id2label, dict):\n",
    "            for i in range(len(id2label)):\n",
    "                label_set.add(id2label[i])\n",
    "        else:\n",
    "            label_set.update(id2label)\n",
    "    global_labels = (['O'] + sorted([l for l in label_set if l != 'O'])) if 'O' in label_set else sorted(label_set)\n",
    "    label2idx = {lab: i for i, lab in enumerate(global_labels)}\n",
    "\n",
    "    local2global = []\n",
    "    for m in models:\n",
    "        id2label = m.config.id2label\n",
    "        if isinstance(id2label, dict):\n",
    "            local = [label2idx[id2label[i]] for i in range(len(id2label))]\n",
    "        else:\n",
    "            local = [label2idx[l] for l in id2label]\n",
    "        local2global.append(torch.tensor(local, dtype=torch.long))\n",
    "\n",
    "    L = len(global_labels)\n",
    "    O_idx = label2idx.get('O', 0)\n",
    "    o_vec = torch.zeros(L, dtype=torch.float32)\n",
    "    o_vec[O_idx] = 1.0\n",
    "\n",
    "    labels_per_text = [None] * len(texts_list)\n",
    "\n",
    "    for b in range(0, len(texts_list), batch_size):\n",
    "        batch_words = words_per_text[b:b + batch_size]\n",
    "\n",
    "        per_model_word_probs = []\n",
    "        for mi, (m, tok) in enumerate(zip(models, tokenizers)):\n",
    "            enc = tok(\n",
    "                batch_words,\n",
    "                is_split_into_words=True,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "            )\n",
    "            word_ids_list = [enc.word_ids(batch_index=i) for i in range(len(batch_words))]\n",
    "            m_device = next(m.parameters()).device\n",
    "            enc_gpu = {k: v.to(m_device) for k, v in enc.items()}\n",
    "            with torch.inference_mode():\n",
    "                logits = m(**enc_gpu).logits\n",
    "                probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            map_idx = local2global[mi].to(probs.device)\n",
    "            gprobs = torch.zeros(probs.size(0), probs.size(1), L, device=probs.device, dtype=probs.dtype)\n",
    "            gprobs.scatter_add_(dim=-1, index=map_idx.view(1, 1, -1).expand_as(probs), src=probs)\n",
    "            gprobs = gprobs.float().cpu()\n",
    "\n",
    "            model_word_probs = []\n",
    "            for si, wids in enumerate(word_ids_list):\n",
    "                arr = [None] * len(batch_words[si])\n",
    "                gp = gprobs[si]\n",
    "                for ti, wid in enumerate(wids):\n",
    "                    if wid is None:\n",
    "                        continue\n",
    "                    if 0 <= wid < len(arr) and arr[wid] is None:\n",
    "                        arr[wid] = gp[ti]\n",
    "                for wi in range(len(arr)):\n",
    "                    if arr[wi] is None:\n",
    "                        arr[wi] = o_vec\n",
    "                model_word_probs.append(arr)\n",
    "            per_model_word_probs.append(model_word_probs)\n",
    "\n",
    "        for si in range(len(batch_words)):\n",
    "            seq_len = len(batch_words[si])\n",
    "            seq_labels = []\n",
    "            for wi in range(seq_len):\n",
    "                vecs = [per_model_word_probs[mj][si][wi] for mj in range(len(models))]\n",
    "                mean_vec = torch.stack(vecs, dim=0).mean(dim=0)\n",
    "                seq_labels.append(global_labels[int(mean_vec.argmax().item())])\n",
    "            labels_per_text[b + si] = seq_labels\n",
    "\n",
    "    results = []\n",
    "    for i, labs in enumerate(labels_per_text):\n",
    "        labs = _fix_bio(labs)\n",
    "        spans = spans_per_text[i]\n",
    "        results.append([(start, end, lab) for (_, start, end), lab in zip(spans, labs)])\n",
    "\n",
    "    return results[0] if single_input else results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T19:47:40.439335Z",
     "iopub.status.busy": "2025-10-01T19:47:40.438700Z",
     "iopub.status.idle": "2025-10-01T19:47:40.446887Z",
     "shell.execute_reply": "2025-10-01T19:47:40.446308Z",
     "shell.execute_reply.started": "2025-10-01T19:47:40.439313Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def f1_macro(labels, preds):\n",
    "  ents = {\n",
    "      'TYPE' : [0, 0, 0],\n",
    "      'BRAND' : [0, 0, 0],\n",
    "      'VOLUME' : [0, 0, 0],\n",
    "      'PERCENT' :  [0,0,0]\n",
    "  }\n",
    "  for tr, pr in zip(labels, preds):\n",
    "    ents_cur = {\n",
    "      'TYPE' : [0, 0, 0],\n",
    "      'BRAND' : [0, 0, 0],\n",
    "      'VOLUME' : [0, 0, 0],\n",
    "      'O' : [0,0,0],\n",
    "      'PERCENT' :  [0,0,0]\n",
    "    }\n",
    "    used = []\n",
    "    for tr_i in tr:\n",
    "      flg = 0\n",
    "      for pr_i in pr:\n",
    "        if pr_i == tr_i:\n",
    "          if sum(ents_cur[tr_i[2].split('-')[-1]]) == 0:\n",
    "            ents_cur[tr_i[2].split('-')[-1]][0] = 1\n",
    "          used.append(tr_i[2].split('-')[-1])\n",
    "          flg = 1\n",
    "          break\n",
    "      if flg == 0:\n",
    "        ents_cur[tr_i[2].split('-')[-1]][2] = 1\n",
    "    for pr_i in pr:\n",
    "      ent = pr_i[2].split('-')[-1]\n",
    "      if ent not in used:\n",
    "        ents_cur[ent][1] = 1\n",
    "    for ent in ['TYPE', 'BRAND', 'VOLUME', 'PERCENT']:\n",
    "      ents[ent][0] += ents_cur[ent][0]\n",
    "      ents[ent][1] += ents_cur[ent][1]\n",
    "      ents[ent][2] += ents_cur[ent][2]\n",
    "  f1s = []\n",
    "  for ent in ['TYPE', 'BRAND', 'VOLUME', 'PERCENT']:\n",
    "    TP = ents[ent][0]\n",
    "    FP = ents[ent][1]\n",
    "    FN = ents[ent][2]\n",
    "    if FP + TP + FN != 0:\n",
    "      if FP + TP == 0 or FN + TP == 0 or TP == 0:\n",
    "        f1s.append(0)\n",
    "      else:\n",
    "        rec = TP / (FP + TP)\n",
    "        pre = TP / (FN + TP)\n",
    "        f1s.append(2*rec*pre/(rec+pre)) \n",
    "  return np.mean(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T19:47:44.448689Z",
     "iopub.status.busy": "2025-10-01T19:47:44.448394Z",
     "iopub.status.idle": "2025-10-01T19:47:44.456630Z",
     "shell.execute_reply": "2025-10-01T19:47:44.455998Z",
     "shell.execute_reply.started": "2025-10-01T19:47:44.448671Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "def _fix_bio(labels):\n",
    "    fixed = []\n",
    "    prev_type = None\n",
    "    inside = False\n",
    "    for lab in labels:\n",
    "        if lab is None or lab == \"O\":\n",
    "            fixed.append(\"O\")\n",
    "            prev_type, inside = None, False\n",
    "            continue\n",
    "\n",
    "        if \"-\" in lab:\n",
    "            prefix, typ = lab.split(\"-\", 1)\n",
    "        else:\n",
    "            prefix, typ = \"B\", lab\n",
    "\n",
    "        if prefix == \"I\" and (not inside or prev_type != typ):\n",
    "            fixed.append(f\"B-{typ}\")\n",
    "            prev_type, inside = typ, True\n",
    "        else:\n",
    "            fixed.append(f\"{prefix}-{typ}\")\n",
    "            inside = prefix in (\"B\", \"I\")\n",
    "            prev_type = typ if inside else None\n",
    "    return fixed\n",
    "\n",
    "def _pieces_per_word(word):\n",
    "    return len(tokenizer(word, add_special_tokens=False)[\"input_ids\"]) or 1\n",
    "\n",
    "def _chunk_words(words, max_pieces):\n",
    "    chunk, cur = [], 0\n",
    "    for w in words:\n",
    "        n = _pieces_per_word(w)\n",
    "        if chunk and cur + n > max_pieces:\n",
    "            yield chunk\n",
    "            chunk, cur = [w], n\n",
    "        else:\n",
    "            chunk.append(w)\n",
    "            cur += n\n",
    "    if chunk:\n",
    "        yield chunk\n",
    "\n",
    "def post_proc(val_predicts):\n",
    "    val_predicts_new = []\n",
    "    for tripls in val_predicts:\n",
    "        row,used = [],[]\n",
    "        for i,j,k in tripls:\n",
    "            if k == 'O':\n",
    "                row.append((i,j,k))\n",
    "                continue\n",
    "            tp = k.split('-')[1]\n",
    "            if tp in used:\n",
    "                row.append((i,j,k.replace('B-','I-')))\n",
    "            else:\n",
    "                row.append((i,j,k.replace('I-','B-')))\n",
    "            used.append(tp)\n",
    "        val_predicts_new.append(row)\n",
    "    return val_predicts_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:02:02.435309Z",
     "iopub.status.busy": "2025-10-01T20:02:02.434812Z",
     "iopub.status.idle": "2025-10-01T20:02:02.441606Z",
     "shell.execute_reply": "2025-10-01T20:02:02.440983Z",
     "shell.execute_reply.started": "2025-10-01T20:02:02.435286Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "def compute_metrics_fn(p):\n",
    "    global epoch\n",
    "    preds, labels = p\n",
    "    preds = np.argmax(preds, axis=2)checkpoints\n",
    "    true_preds, true_labels = [], []\n",
    "    for pred_seq, lab_seq in zip(preds, labels):\n",
    "        pred_tags, lab_tags = [], []\n",
    "        for p_i, l_i in zip(pred_seq, lab_seq):\n",
    "            if l_i == -100:\n",
    "                continue\n",
    "            pred_tags.append(id2label[p_i])\n",
    "            lab_tags.append(id2label[l_i])\n",
    "        true_preds.append(pred_tags)\n",
    "        true_labels.append(lab_tags)\n",
    "    print(classification_report(true_labels, true_preds))\n",
    "    seq_eval_metrics =  {\n",
    "        \"precision\": precision_score(true_labels, true_preds),\n",
    "        \"recall\":    recall_score(true_labels, true_preds),\n",
    "        \"f1\":        f1_score(true_labels, true_preds, average='macro'),\n",
    "        \"accuracy\":  accuracy_score(true_labels, true_preds),\n",
    "    }\n",
    "    val_preds = post_proc(ner_word_tuples(valid_samples, model, tokenizer, batch_size=128))\n",
    "    seq_eval_metrics['f1_word_level'] = f1_macro(valid_annotation,val_preds)\n",
    "\n",
    "    test_preds = post_proc(ner_word_tuples(sample_sub['sample'].tolist(), model, tokenizer, batch_size=128))\n",
    "    sample_sub['annotation'] = test_preds\n",
    "    model.save_pretrained(f'checkpoints/ckpt_{epoch}')\n",
    "    epoch += 1\n",
    "    return seq_eval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:02:31.016571Z",
     "iopub.status.busy": "2025-10-01T20:02:31.016040Z",
     "iopub.status.idle": "2025-10-01T20:02:32.541322Z",
     "shell.execute_reply": "2025-10-01T20:02:32.540730Z",
     "shell.execute_reply.started": "2025-10-01T20:02:31.016551Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "set_seed(SEED)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"microsoft/mdeberta-v3-base\",\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:02:34.943101Z",
     "iopub.status.busy": "2025-10-01T20:02:34.942578Z",
     "iopub.status.idle": "2025-10-01T20:02:34.984497Z",
     "shell.execute_reply": "2025-10-01T20:02:34.983910Z",
     "shell.execute_reply.started": "2025-10-01T20:02:34.943080Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"ruberta_ner\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=224,\n",
    "    per_device_eval_batch_size=256,\n",
    "    save_total_limit=1,\n",
    "    num_train_epochs=30,\n",
    "    weight_decay=0.0,\n",
    "    warmup_ratio=0.1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    group_by_length=True,\n",
    "    fp16=False,  \n",
    "    report_to=\"none\",\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T20:02:35.398451Z",
     "iopub.status.busy": "2025-10-01T20:02:35.397838Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_196/319298311.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2705' max='3120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2705/3120 40:03 < 06:09, 1.12 it/s, Epoch 26/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Word Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.456900</td>\n",
       "      <td>0.306687</td>\n",
       "      <td>0.909181</td>\n",
       "      <td>0.935120</td>\n",
       "      <td>0.439481</td>\n",
       "      <td>0.909421</td>\n",
       "      <td>0.445769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.217800</td>\n",
       "      <td>0.246718</td>\n",
       "      <td>0.934195</td>\n",
       "      <td>0.955506</td>\n",
       "      <td>0.690188</td>\n",
       "      <td>0.933553</td>\n",
       "      <td>0.613888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.171700</td>\n",
       "      <td>0.222568</td>\n",
       "      <td>0.941370</td>\n",
       "      <td>0.956855</td>\n",
       "      <td>0.877806</td>\n",
       "      <td>0.939259</td>\n",
       "      <td>0.833363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.119400</td>\n",
       "      <td>0.212708</td>\n",
       "      <td>0.947486</td>\n",
       "      <td>0.963327</td>\n",
       "      <td>0.884369</td>\n",
       "      <td>0.945691</td>\n",
       "      <td>0.839678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.082400</td>\n",
       "      <td>0.266270</td>\n",
       "      <td>0.947519</td>\n",
       "      <td>0.962032</td>\n",
       "      <td>0.876403</td>\n",
       "      <td>0.945062</td>\n",
       "      <td>0.829516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.066200</td>\n",
       "      <td>0.277925</td>\n",
       "      <td>0.948242</td>\n",
       "      <td>0.964351</td>\n",
       "      <td>0.878038</td>\n",
       "      <td>0.945933</td>\n",
       "      <td>0.832043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.301086</td>\n",
       "      <td>0.946720</td>\n",
       "      <td>0.961169</td>\n",
       "      <td>0.877874</td>\n",
       "      <td>0.942741</td>\n",
       "      <td>0.833629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>0.337069</td>\n",
       "      <td>0.945367</td>\n",
       "      <td>0.966832</td>\n",
       "      <td>0.904609</td>\n",
       "      <td>0.945159</td>\n",
       "      <td>0.881344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.400483</td>\n",
       "      <td>0.945270</td>\n",
       "      <td>0.966886</td>\n",
       "      <td>0.880201</td>\n",
       "      <td>0.946078</td>\n",
       "      <td>0.835939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.340744</td>\n",
       "      <td>0.946342</td>\n",
       "      <td>0.963542</td>\n",
       "      <td>0.877625</td>\n",
       "      <td>0.945401</td>\n",
       "      <td>0.830101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>0.416186</td>\n",
       "      <td>0.948970</td>\n",
       "      <td>0.966832</td>\n",
       "      <td>0.886436</td>\n",
       "      <td>0.946658</td>\n",
       "      <td>0.841192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.420038</td>\n",
       "      <td>0.947097</td>\n",
       "      <td>0.970338</td>\n",
       "      <td>0.921718</td>\n",
       "      <td>0.947722</td>\n",
       "      <td>0.904652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.018700</td>\n",
       "      <td>0.377420</td>\n",
       "      <td>0.949889</td>\n",
       "      <td>0.969151</td>\n",
       "      <td>0.900582</td>\n",
       "      <td>0.949366</td>\n",
       "      <td>0.869316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.397402</td>\n",
       "      <td>0.948863</td>\n",
       "      <td>0.969690</td>\n",
       "      <td>0.898508</td>\n",
       "      <td>0.949608</td>\n",
       "      <td>0.866208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.445677</td>\n",
       "      <td>0.948387</td>\n",
       "      <td>0.967210</td>\n",
       "      <td>0.882212</td>\n",
       "      <td>0.947384</td>\n",
       "      <td>0.836435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.468994</td>\n",
       "      <td>0.948183</td>\n",
       "      <td>0.968126</td>\n",
       "      <td>0.891131</td>\n",
       "      <td>0.947916</td>\n",
       "      <td>0.853324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.430784</td>\n",
       "      <td>0.950724</td>\n",
       "      <td>0.963542</td>\n",
       "      <td>0.885109</td>\n",
       "      <td>0.946513</td>\n",
       "      <td>0.850570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.430744</td>\n",
       "      <td>0.951282</td>\n",
       "      <td>0.964621</td>\n",
       "      <td>0.893612</td>\n",
       "      <td>0.947916</td>\n",
       "      <td>0.860746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.454922</td>\n",
       "      <td>0.950053</td>\n",
       "      <td>0.968396</td>\n",
       "      <td>0.891870</td>\n",
       "      <td>0.949270</td>\n",
       "      <td>0.853954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.470219</td>\n",
       "      <td>0.948009</td>\n",
       "      <td>0.966670</td>\n",
       "      <td>0.890771</td>\n",
       "      <td>0.946030</td>\n",
       "      <td>0.852535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.485038</td>\n",
       "      <td>0.949474</td>\n",
       "      <td>0.967857</td>\n",
       "      <td>0.913532</td>\n",
       "      <td>0.948012</td>\n",
       "      <td>0.896288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.472617</td>\n",
       "      <td>0.952057</td>\n",
       "      <td>0.966023</td>\n",
       "      <td>0.886127</td>\n",
       "      <td>0.948206</td>\n",
       "      <td>0.846319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.474851</td>\n",
       "      <td>0.951497</td>\n",
       "      <td>0.968072</td>\n",
       "      <td>0.912624</td>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.892039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.493868</td>\n",
       "      <td>0.951431</td>\n",
       "      <td>0.966670</td>\n",
       "      <td>0.883712</td>\n",
       "      <td>0.948157</td>\n",
       "      <td>0.842615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.508695</td>\n",
       "      <td>0.949427</td>\n",
       "      <td>0.968935</td>\n",
       "      <td>0.907801</td>\n",
       "      <td>0.948399</td>\n",
       "      <td>0.881940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.87      0.76      0.81      3445\n",
      "     PERCENT       0.00      0.00      0.00        21\n",
      "        TYPE       0.92      0.98      0.95     15042\n",
      "      VOLUME       0.00      0.00      0.00        34\n",
      "\n",
      "   micro avg       0.91      0.94      0.92     18542\n",
      "   macro avg       0.45      0.43      0.44     18542\n",
      "weighted avg       0.91      0.94      0.92     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.84      0.92      0.88      3445\n",
      "     PERCENT       0.42      0.95      0.58        21\n",
      "        TYPE       0.96      0.97      0.96     15042\n",
      "      VOLUME       1.00      0.21      0.34        34\n",
      "\n",
      "   micro avg       0.93      0.96      0.94     18542\n",
      "   macro avg       0.80      0.76      0.69     18542\n",
      "weighted avg       0.94      0.96      0.95     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.94      0.83      0.88      3445\n",
      "     PERCENT       0.69      0.95      0.80        21\n",
      "        TYPE       0.94      0.99      0.96     15042\n",
      "      VOLUME       1.00      0.76      0.87        34\n",
      "\n",
      "   micro avg       0.94      0.96      0.95     18542\n",
      "   macro avg       0.89      0.88      0.88     18542\n",
      "weighted avg       0.94      0.96      0.95     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.93      0.88      0.90      3445\n",
      "     PERCENT       0.69      0.95      0.80        21\n",
      "        TYPE       0.95      0.98      0.97     15042\n",
      "      VOLUME       1.00      0.76      0.87        34\n",
      "\n",
      "   micro avg       0.95      0.96      0.96     18542\n",
      "   macro avg       0.89      0.89      0.88     18542\n",
      "weighted avg       0.95      0.96      0.95     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.92      0.87      0.90      3445\n",
      "     PERCENT       0.68      0.90      0.78        21\n",
      "        TYPE       0.95      0.98      0.97     15042\n",
      "      VOLUME       1.00      0.76      0.87        34\n",
      "\n",
      "   micro avg       0.95      0.96      0.95     18542\n",
      "   macro avg       0.89      0.88      0.88     18542\n",
      "weighted avg       0.95      0.96      0.95     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.93      0.88      0.90      3445\n",
      "     PERCENT       0.68      0.90      0.78        21\n",
      "        TYPE       0.95      0.98      0.97     15042\n",
      "      VOLUME       1.00      0.76      0.87        34\n",
      "\n",
      "   micro avg       0.95      0.96      0.96     18542\n",
      "   macro avg       0.89      0.88      0.88     18542\n",
      "weighted avg       0.95      0.96      0.96     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.93      0.86      0.89      3445\n",
      "     PERCENT       0.67      0.95      0.78        21\n",
      "        TYPE       0.95      0.98      0.97     15042\n",
      "      VOLUME       1.00      0.76      0.87        34\n",
      "\n",
      "   micro avg       0.95      0.96      0.95     18542\n",
      "   macro avg       0.89      0.89      0.88     18542\n",
      "weighted avg       0.95      0.96      0.95     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.93      0.87      0.90      3445\n",
      "     PERCENT       0.76      0.90      0.83        21\n",
      "        TYPE       0.95      0.99      0.97     15042\n",
      "      VOLUME       0.97      0.88      0.92        34\n",
      "\n",
      "   micro avg       0.95      0.97      0.96     18542\n",
      "   macro avg       0.90      0.91      0.90     18542\n",
      "weighted avg       0.95      0.97      0.96     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.90      0.90      0.90      3445\n",
      "     PERCENT       0.67      0.95      0.78        21\n",
      "        TYPE       0.96      0.98      0.97     15042\n",
      "      VOLUME       1.00      0.76      0.87        34\n",
      "\n",
      "   micro avg       0.95      0.97      0.96     18542\n",
      "   macro avg       0.88      0.90      0.88     18542\n",
      "weighted avg       0.95      0.97      0.96     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.89      0.92      0.90      3445\n",
      "     PERCENT       0.68      0.90      0.78        21\n",
      "        TYPE       0.96      0.98      0.97     15042\n",
      "      VOLUME       1.00      0.76      0.87        34\n",
      "\n",
      "   micro avg       0.95      0.96      0.95     18542\n",
      "   macro avg       0.88      0.89      0.88     18542\n",
      "weighted avg       0.95      0.96      0.95     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.90      0.92      0.91      3445\n",
      "     PERCENT       0.69      0.95      0.80        21\n",
      "        TYPE       0.96      0.98      0.97     15042\n",
      "      VOLUME       1.00      0.76      0.87        34\n",
      "\n",
      "   micro avg       0.95      0.97      0.96     18542\n",
      "   macro avg       0.89      0.90      0.89     18542\n",
      "weighted avg       0.95      0.97      0.96     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.93      0.89      0.91      3445\n",
      "     PERCENT       0.80      0.95      0.87        21\n",
      "        TYPE       0.95      0.99      0.97     15042\n",
      "      VOLUME       1.00      0.88      0.94        34\n",
      "\n",
      "   micro avg       0.95      0.97      0.96     18542\n",
      "   macro avg       0.92      0.93      0.92     18542\n",
      "weighted avg       0.95      0.97      0.96     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.90      0.92      0.91      3445\n",
      "     PERCENT       0.71      0.95      0.82        21\n",
      "        TYPE       0.96      0.98      0.97     15042\n",
      "      VOLUME       1.00      0.82      0.90        34\n",
      "\n",
      "   micro avg       0.95      0.97      0.96     18542\n",
      "   macro avg       0.89      0.92      0.90     18542\n",
      "weighted avg       0.95      0.97      0.96     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.92      0.90      0.91      3445\n",
      "     PERCENT       0.73      0.90      0.81        21\n",
      "        TYPE       0.95      0.99      0.97     15042\n",
      "      VOLUME       1.00      0.82      0.90        34\n",
      "\n",
      "   micro avg       0.95      0.97      0.96     18542\n",
      "   macro avg       0.90      0.90      0.90     18542\n",
      "weighted avg       0.95      0.97      0.96     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.93      0.89      0.91      3445\n",
      "     PERCENT       0.67      0.95      0.78        21\n",
      "        TYPE       0.95      0.98      0.97     15042\n",
      "      VOLUME       1.00      0.76      0.87        34\n",
      "\n",
      "   micro avg       0.95      0.97      0.96     18542\n",
      "   macro avg       0.89      0.90      0.88     18542\n",
      "weighted avg       0.95      0.97      0.96     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.92      0.90      0.91      3445\n",
      "     PERCENT       0.69      0.95      0.80        21\n",
      "        TYPE       0.96      0.98      0.97     15042\n",
      "      VOLUME       1.00      0.79      0.89        34\n",
      "\n",
      "   micro avg       0.95      0.97      0.96     18542\n",
      "   macro avg       0.89      0.91      0.89     18542\n",
      "weighted avg       0.95      0.97      0.96     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.89      0.92      0.91      3445\n",
      "     PERCENT       0.73      0.76      0.74        21\n",
      "        TYPE       0.96      0.97      0.97     15042\n",
      "      VOLUME       1.00      0.85      0.92        34\n",
      "\n",
      "   micro avg       0.95      0.96      0.96     18542\n",
      "   macro avg       0.90      0.88      0.89     18542\n",
      "weighted avg       0.95      0.96      0.96     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.91      0.91      0.91      3445\n",
      "     PERCENT       0.70      0.90      0.79        21\n",
      "        TYPE       0.96      0.98      0.97     15042\n",
      "      VOLUME       1.00      0.82      0.90        34\n",
      "\n",
      "   micro avg       0.95      0.96      0.96     18542\n",
      "   macro avg       0.89      0.90      0.89     18542\n",
      "weighted avg       0.95      0.96      0.96     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.92      0.90      0.91      3445\n",
      "     PERCENT       0.69      0.95      0.80        21\n",
      "        TYPE       0.96      0.98      0.97     15042\n",
      "      VOLUME       1.00      0.79      0.89        34\n",
      "\n",
      "   micro avg       0.95      0.97      0.96     18542\n",
      "   macro avg       0.89      0.91      0.89     18542\n",
      "weighted avg       0.95      0.97      0.96     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.92      0.90      0.91      3445\n",
      "     PERCENT       0.69      0.95      0.80        21\n",
      "        TYPE       0.95      0.98      0.97     15042\n",
      "      VOLUME       1.00      0.79      0.89        34\n",
      "\n",
      "   micro avg       0.95      0.97      0.96     18542\n",
      "   macro avg       0.89      0.91      0.89     18542\n",
      "weighted avg       0.95      0.97      0.96     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.93      0.90      0.91      3445\n",
      "     PERCENT       0.78      0.86      0.82        21\n",
      "        TYPE       0.95      0.98      0.97     15042\n",
      "      VOLUME       1.00      0.91      0.95        34\n",
      "\n",
      "   micro avg       0.95      0.97      0.96     18542\n",
      "   macro avg       0.92      0.91      0.91     18542\n",
      "weighted avg       0.95      0.97      0.96     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.92      0.91      0.91      3445\n",
      "     PERCENT       0.68      0.90      0.78        21\n",
      "        TYPE       0.96      0.98      0.97     15042\n",
      "      VOLUME       1.00      0.79      0.89        34\n",
      "\n",
      "   micro avg       0.95      0.97      0.96     18542\n",
      "   macro avg       0.89      0.90      0.89     18542\n",
      "weighted avg       0.95      0.97      0.96     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.93      0.91      0.92      3445\n",
      "     PERCENT       0.76      0.90      0.83        21\n",
      "        TYPE       0.96      0.98      0.97     15042\n",
      "      VOLUME       1.00      0.88      0.94        34\n",
      "\n",
      "   micro avg       0.95      0.97      0.96     18542\n",
      "   macro avg       0.91      0.92      0.91     18542\n",
      "weighted avg       0.95      0.97      0.96     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.93      0.90      0.91      3445\n",
      "     PERCENT       0.69      0.86      0.77        21\n",
      "        TYPE       0.96      0.98      0.97     15042\n",
      "      VOLUME       1.00      0.79      0.89        34\n",
      "\n",
      "   micro avg       0.95      0.97      0.96     18542\n",
      "   macro avg       0.89      0.88      0.88     18542\n",
      "weighted avg       0.95      0.97      0.96     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.92      0.91      0.92      3445\n",
      "     PERCENT       0.76      0.90      0.83        21\n",
      "        TYPE       0.96      0.98      0.97     15042\n",
      "      VOLUME       1.00      0.85      0.92        34\n",
      "\n",
      "   micro avg       0.95      0.97      0.96     18542\n",
      "   macro avg       0.91      0.91      0.91     18542\n",
      "weighted avg       0.95      0.97      0.96     18542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       BRAND       0.93      0.91      0.92      3445\n",
      "     PERCENT       0.77      0.95      0.85        21\n",
      "        TYPE       0.96      0.98      0.97     15042\n",
      "      VOLUME       1.00      0.88      0.94        34\n",
      "\n",
      "   micro avg       0.95      0.97      0.96     18542\n",
      "   macro avg       0.91      0.93      0.92     18542\n",
      "weighted avg       0.95      0.97      0.96     18542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_seed(SEED)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics_fn,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_13 = AutoModelForTokenClassification.from_pretrained('checkpoints/ckpt_13').cuda().state_dict()\n",
    "model_16 = AutoModelForTokenClassification.from_pretrained('checkpoints/ckpt_16').cuda().state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_state_dict = {}\n",
    "for k in model_13:\n",
    "    new_state_dict[k] = (model_13[k] + model_16[k]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'deberta_without_bio.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaL4",
   "dataSources": [
    {
     "databundleVersionId": 11802066,
     "isSourceIdPinned": false,
     "sourceId": 91496,
     "sourceType": "competition"
    },
    {
     "datasetId": 8347497,
     "sourceId": 13172877,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8373140,
     "sourceId": 13210636,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8380558,
     "sourceId": 13221465,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8384728,
     "sourceId": 13227966,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "m_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
